{"name":"多模态","slug":"多模态","count":5,"postlist":[{"title":"BLIP论文精读","uid":"8c1dec7477178f4dfc0f70f9822eceb4","slug":"BLIP论文精读","date":"2025-07-06T01:10:15.000Z","updated":"2025-07-07T06:29:04.596Z","comments":true,"path":"api/articles/BLIP论文精读.json","keywords":null,"cover":"https://i.imgur.com/A0oc13X_d.png?maxwidth=520&shape=thumb&fidelity=high","text":"论文提出 BLIP 框架，用 MED 模型和 CapFilt 方法处理噪声数据，在多视觉语言任务达 SOTA，可零样本迁移至视频任务...","permalink":"/post/BLIP论文精读","photos":[],"count_time":{"symbolsCount":"20k","symbolsTime":"18 mins."},"categories":[{"name":"论文精读","slug":"论文精读","count":6,"path":"api/categories/论文精读.json"}],"tags":[{"name":"多模态","slug":"多模态","count":5,"path":"api/tags/多模态.json"},{"name":"BLIP","slug":"BLIP","count":2,"path":"api/tags/BLIP.json"}],"author":{"name":"犬夜叉","slug":"blog-author","avatar":"https://i.imgur.com/CrgPA5H_d.png?maxwidth=520&shape=thumb&fidelity=high","link":"/","description":"一位喜欢犬夜叉的多模态大模型研究生","socials":{"github":"https://github.com/ziyi-wang2003","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/qq_62954485?spm=1000.2115.3001.5343","juejin":"","customs":{}}},"feature":true},{"title":"Flamingo论文精读","uid":"b18ad5e5297b60924e424af2ef6c52c5","slug":"flamingo论文精读","date":"2025-07-05T02:32:50.000Z","updated":"2025-07-07T06:29:11.698Z","comments":true,"path":"api/articles/flamingo论文精读.json","keywords":null,"cover":"https://i.imgur.com/CseN8ka.png?maxwidth=520&shape=thumb&fidelity=high","text":"Flamingo 是一种能通过少量标注示例快速适应新任务的视觉语言模型。其架构创新在于连接预训练视觉和语言模型、处理图文交错序列及接收图像视频输入。经大规模多模态网络语料训练后，在视觉问答、字幕生成等任务上少样本学习表现优异，超越需大量数据微调的模型。...","permalink":"/post/flamingo论文精读","photos":[],"count_time":{"symbolsCount":"11k","symbolsTime":"10 mins."},"categories":[{"name":"论文精读","slug":"论文精读","count":6,"path":"api/categories/论文精读.json"}],"tags":[{"name":"多模态","slug":"多模态","count":5,"path":"api/tags/多模态.json"},{"name":"小样本","slug":"小样本","count":1,"path":"api/tags/小样本.json"}],"author":{"name":"犬夜叉","slug":"blog-author","avatar":"https://i.imgur.com/CrgPA5H_d.png?maxwidth=520&shape=thumb&fidelity=high","link":"/","description":"一位喜欢犬夜叉的多模态大模型研究生","socials":{"github":"https://github.com/ziyi-wang2003","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/qq_62954485?spm=1000.2115.3001.5343","juejin":"","customs":{}}},"feature":true},{"title":"ALBEF论文精读","uid":"5cac6105e8bc407ec91f6896ed602917","slug":"ALBEF论文精读","date":"2025-07-03T03:20:45.000Z","updated":"2025-07-07T06:29:20.677Z","comments":true,"path":"api/articles/ALBEF论文精读.json","keywords":null,"cover":"https://i.imgur.com/GDGylHi_d.png?maxwidth=520&shape=thumb&fidelity=high","text":"论文提出 ALBEF 框架，通过对比损失对齐图文表示，结合动量蒸馏处理噪声数据，在多任务上性能优于 SOTA。...","permalink":"/post/ALBEF论文精读","photos":[],"count_time":{"symbolsCount":"8.3k","symbolsTime":"8 mins."},"categories":[{"name":"论文精读","slug":"论文精读","count":6,"path":"api/categories/论文精读.json"}],"tags":[{"name":"多模态","slug":"多模态","count":5,"path":"api/tags/多模态.json"},{"name":"VLP","slug":"VLP","count":2,"path":"api/tags/VLP.json"}],"author":{"name":"犬夜叉","slug":"blog-author","avatar":"https://i.imgur.com/CrgPA5H_d.png?maxwidth=520&shape=thumb&fidelity=high","link":"/","description":"一位喜欢犬夜叉的多模态大模型研究生","socials":{"github":"https://github.com/ziyi-wang2003","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/qq_62954485?spm=1000.2115.3001.5343","juejin":"","customs":{}}},"feature":true},{"title":"ViLT 论文精读","uid":"8c60d49e88f3e150291142683c6b267b","slug":"ViLT论文精读","date":"2025-07-02T09:37:29.000Z","updated":"2025-07-06T10:27:59.134Z","comments":true,"path":"api/articles/ViLT论文精读.json","keywords":null,"cover":"https://i.imgur.com/HUxHipu.png?maxwidth=520&shape=thumb&fidelity=high","text":"ViLT是一种高效的多模态模型，旨在简化视觉与语言的融合。它无需复杂的独立视觉特征提取器，直接在统一的Transformer中处理图像块和文本，显著提升了模型训练和推理的速度。...","permalink":"/post/ViLT论文精读","photos":[],"count_time":{"symbolsCount":"7.1k","symbolsTime":"6 mins."},"categories":[{"name":"论文精读","slug":"论文精读","count":6,"path":"api/categories/论文精读.json"}],"tags":[{"name":"多模态","slug":"多模态","count":5,"path":"api/tags/多模态.json"},{"name":"VLP","slug":"VLP","count":2,"path":"api/tags/VLP.json"}],"author":{"name":"犬夜叉","slug":"blog-author","avatar":"https://i.imgur.com/CrgPA5H_d.png?maxwidth=520&shape=thumb&fidelity=high","link":"/","description":"一位喜欢犬夜叉的多模态大模型研究生","socials":{"github":"https://github.com/ziyi-wang2003","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/qq_62954485?spm=1000.2115.3001.5343","juejin":"","customs":{}}}},{"title":"CLIP 论文精读","uid":"64c2453c0ac7d584fda9903cba47649e","slug":"CLIP论文精读","date":"2025-07-02T08:41:41.000Z","updated":"2025-07-06T10:28:08.143Z","comments":true,"path":"api/articles/CLIP论文精读.json","keywords":null,"cover":"https://i.imgur.com/2MusSpQ.png?maxwidth=520&shape=thumb&fidelity=high","text":"CLIP是OpenAI开发的多模态模型，能理解图像和文本的关联。它通过对比学习，将图文映射到同一空间，实现出色的零样本图像分类能力。...","permalink":"/post/CLIP论文精读","photos":[],"count_time":{"symbolsCount":"3.4k","symbolsTime":"3 mins."},"categories":[{"name":"论文精读","slug":"论文精读","count":6,"path":"api/categories/论文精读.json"}],"tags":[{"name":"多模态","slug":"多模态","count":5,"path":"api/tags/多模态.json"},{"name":"对比学习","slug":"对比学习","count":1,"path":"api/tags/对比学习.json"}],"author":{"name":"犬夜叉","slug":"blog-author","avatar":"https://i.imgur.com/CrgPA5H_d.png?maxwidth=520&shape=thumb&fidelity=high","link":"/","description":"一位喜欢犬夜叉的多模态大模型研究生","socials":{"github":"https://github.com/ziyi-wang2003","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/qq_62954485?spm=1000.2115.3001.5343","juejin":"","customs":{}}}}]}