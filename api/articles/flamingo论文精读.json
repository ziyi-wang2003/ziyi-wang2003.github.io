{"title":"flamingo论文精读","uid":"db8c465178376c09ae44121bab3afad6","slug":"flamingo论文精读","date":"2025-07-05T02:32:50.000Z","updated":"2025-07-05T04:16:05.097Z","comments":true,"path":"api/articles/flamingo论文精读.json","keywords":null,"cover":[],"content":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><h2 id=\"1-核心挑战与现有方法的局限性\"><a href=\"#1-核心挑战与现有方法的局限性\" class=\"headerlink\" title=\"1. 核心挑战与现有方法的局限性\"></a>1. 核心挑战与现有方法的局限性</h2><p>多模态机器学习领域面临一个核心的开放性挑战：<strong>如何构建能够仅凭少数几个标注样本就迅速适应新任务的模型</strong>。 这种快速学习能力是智能的一个关键特征，即在接收到简短指令后能学会执行新任务。 </p>\n<p>目前，计算机视觉领域最广泛应用的范式仍然是“预训练-微调”（pre-training and fine-tuning）。 这个过程通常包括两个阶段：</p>\n<ol>\n<li><strong>预训练阶段</strong>：在一个大规模的、有监督的数据集上预先训练模型。</li>\n<li><strong>微调阶段</strong>：在目标任务的特定数据集上对预训练好的模型进行参数微调。 </li>\n</ol>\n<p>然而，这种主流范式存在显著的缺点：</p>\n<ul>\n<li><p><strong>数据依赖性强</strong>：成功的微调往往需要成千上万个为特定任务标注的数据点，获取这些数据成本高昂。</p>\n</li>\n<li><p><strong>高昂的调优成本</strong>：针对每个新任务，都需要进行仔细的超参数调整，这是一个繁琐且耗费计算资源的过程。</p>\n</li>\n<li><p><strong>资源密集</strong>：整个微调过程需要大量的计算资源。</p>\n</li>\n</ul>\n<p>为了克服微调的限制，近年来出现了一些新的方法，但它们同样有其局限性：</p>\n<ul>\n<li><p><strong>对比学习模型 (Contrastive Models)</strong>：像CLIP这样的多模态视觉语言模型，通过对比学习目标进行训练，实现了对新任务的“零样本”适应，无需微调。 它们的工作原理是为文本和图像学习一个共享的嵌入空间，并计算两者之间的相似度分数。 这种机制限制了它们的应用场景，主要适用于分类等选择题式的任务，即从一个预先给定的有限选项中做出选择。 关键的缺陷在于，这类模型<strong>无法生成语言</strong>，这使得它们不适用于更开放式的任务，例如视觉问答（VQA）或图像描述（Captioning），因为这些任务需要模型生成自由形式的文本答案。 </p>\n</li>\n<li><p><strong>视觉条件下的语言生成模型 (Visually-conditioned Language Generation Models)</strong>：虽然有一些研究探索了根据视觉输入生成文本的模型，但这些模型在数据量较少（即小样本）的情况下，尚未展现出足够好的性能。 </p>\n</li>\n</ul>\n<p><img src=\"/post/flamingo%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/file-20250705110517865.png\" alt><br>图1：从Flamingo-80B获得的输入和输出精选示例。Flamingo可通过少样本提示快速适应各种图像/视频理解任务。此外，Flamingo原生支持多图像视觉对话。</p>\n<h2 id=\"2-Flamingo模型的提出与核心能力\"><a href=\"#2-Flamingo模型的提出与核心能力\" class=\"headerlink\" title=\"2. Flamingo模型的提出与核心能力\"></a>2. Flamingo模型的提出与核心能力</h2><p>为了解决上述挑战，本研究引入了一个名为<strong>Flamingo</strong>的视觉语言模型系列。 Flamingo的核心突破在于其卓越的<strong>小样本学习（few-shot learning）能力</strong>。 </p>\n<ul>\n<li><p><strong>工作范式</strong>：Flamingo通过“提示（prompting）”来适应新任务。用户只需向模型提供几个包含输入/输出对的样本（例如，&lt;图片，对应描述&gt; 或 &lt;图片，问答对&gt;），模型就能理解任务要求并对新的查询图片或视频生成相应的文本输出。 1这种方式极大地降低了对大量标注数据的依赖。</p>\n</li>\n<li><p><strong>卓越的性能</strong>：在一个包含16个不同的视觉和语言任务的广泛评测中，Flamingo展现了最先进的小样本学习性能。 更为引人注目的是，在其中的6个任务上，Flamingo仅使用极少数的样本（例如32个），其性能就<strong>超越了在数千甚至数万倍任务专属数据上进行微调的现有最先进模型</strong>。 </p>\n</li>\n</ul>\n<p><img src=\"/post/flamingo%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/file-20250705110030288.png\" alt></p>\n<h2 id=\"3-设计思想：将大语言模型的能力扩展至多模态领域\"><a href=\"#3-设计思想：将大语言模型的能力扩展至多模态领域\" class=\"headerlink\" title=\"3. 设计思想：将大语言模型的能力扩展至多模态领域\"></a>3. 设计思想：将大语言模型的能力扩展至多模态领域</h2><p>Flamingo的设计灵感主要来源于近年来在大型语言模型领域取得的巨大成功，例如GPT-3等模型展现出的强大的小样本学习能力。 </p>\n<ul>\n<li><p><strong>LMs的小样本学习机制</strong>：一个强大的大型语言模型能够仅通过其文本接口来执行多种任务。具体做法是，将任务的几个示例（examples）和新的查询输入（query input）一起打包成一个文本提示（prompt），然后模型会自回归地生成一个续写，这个续写就是对查询的预测输出。 </p>\n</li>\n<li><p><strong>将该机制迁移至视觉任务</strong>：本研究证明，同样的方法论可以被成功地应用于图像和视频理解任务。 像分类、描述生成、视觉问答等任务，都可以被重新定义和构建为<strong>以视觉输入为条件的文本预测问题</strong>。 </p>\n</li>\n<li><p><strong>与纯语言模型的关键区别</strong>：与仅处理文本的LM不同，视觉任务需要模型能够处理一个<strong>多模态的提示（multimodal prompt）</strong>，这个提示中包含了与文本交错在一起的图像或视频。 Flamingo模型的核心能力之一就是<strong>处理这种任意交错的视觉和文本序列</strong>。 </p>\n</li>\n</ul>\n<h2 id=\"4-Flamingo的架构理念与关键组件\"><a href=\"#4-Flamingo的架构理念与关键组件\" class=\"headerlink\" title=\"4. Flamingo的架构理念与关键组件\"></a>4. Flamingo的架构理念与关键组件</h2><p>Flamingo模型是一个能够接收文本、图像、视频交错序列作为输入，并生成自由文本作为输出的<strong>视觉条件自回归文本生成模型</strong>。 其架构设计的核心理念是有效地连接和利用两个强大的、预训练好的互补模型，同时保留它们在各自领域学到的丰富知识。</p>\n<ul>\n<li><p><strong>利用预训练模型</strong>：Flamingo架构的基础是两个<strong>预训练且被冻结（frozen）</strong>的模型：</p>\n<ol>\n<li><p>一个<strong>视觉模型</strong>，负责“感知”视觉场景。 </p>\n</li>\n<li><p>一个<strong>大型语言模型</strong>，负责执行基本的推理和文本生成。 </p>\n</li>\n</ol>\n</li>\n<li><p><strong>创新的桥接设计</strong>：在冻结的视觉和语言模型之间，引入了<strong>全新设计的、从零开始训练的架构组件</strong>。 这种“桥接”方式至关重要，因为它可以在不破坏原有模型知识（防止灾难性遗忘）的前提下，高效地将视觉信息融入到语言模型的处理流程中。 </p>\n</li>\n<li><p><strong>高效处理高分辨率视觉输入</strong>：为了处理高分辨率的图像或视频，Flamingo采用了一个基于<strong>Perceiver的架构</strong>。 该模块可以将视觉编码器产生的大量、可变数量的视觉特征，压缩并重采样成一小组固定数量的“视觉令牌（visual tokens）”。 这一设计极大地提高了处理效率。</p>\n</li>\n</ul>\n<p><img src=\"/post/flamingo%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/file-20250705110431410.png\" alt></p>\n<h2 id=\"5-训练策略的关键性\"><a href=\"#5-训练策略的关键性\" class=\"headerlink\" title=\"5. 训练策略的关键性\"></a>5. 训练策略的关键性</h2><p>大型语言模型的强大性能很大程度上归功于其在海量文本数据上的训练，这赋予了它们通用的文本生成能力，从而在接收到任务提示时表现出色。 </p>\n<ul>\n<li><p><strong>训练数据的重要性</strong>：与此类似，本研究证明，Flamingo模型的训练方式对其最终的性能至关重要。 </p>\n</li>\n<li><p><strong>独特的训练数据</strong>：模型在一个精心挑选的、大规模、多模态的网络语料库上进行训练。这些数据的一个关键特征是包含了<strong>任意交错的文本和图像</strong>，这与传统的成对（image-text pair）数据有本质区别。 </p>\n</li>\n<li><p><strong>实现小样本能力的关键</strong>：正是这种在真实网络页面数据上的训练，才赋予了Flamingo强大的<strong>上下文小样本学习（in-context few-shot learning）能力</strong>。 经过这样的训练后，模型无需任何针对特定任务的微调，就能直接通过小样本提示的方式适应新的视觉任务。 </p>\n</li>\n</ul>\n<h1 id=\"Approach\"><a href=\"#Approach\" class=\"headerlink\" title=\"Approach\"></a>Approach</h1><p>本节详细阐述了Flamingo模型的架构设计、工作原理与训练策略。Flamingo是一个视觉语言模型，其核心功能是接收以任意方式穿插的文本与图像/视频序列作为输入，并以自回归的方式生成自由形式的文本作为输出。模型设计的指导思想是高效地桥接两个强大的、已预训练好的独立模型——一个用于视觉感知的模型和一个用于语言理解与生成的模型，从而在不破坏各自预训练知识的前提下，实现强大的多模态处理能力。</p>\n<h2 id=\"2-1-视觉处理与Perceiver-Resampler模块\"><a href=\"#2-1-视觉处理与Perceiver-Resampler模块\" class=\"headerlink\" title=\"2.1 视觉处理与Perceiver Resampler模块\"></a>2.1 视觉处理与Perceiver Resampler模块</h2><p>视觉信息的处理是整个模型的第一步，其目标是将原始的像素输入转化为紧凑且固定长度的、可供语言模型利用的表征。</p>\n<ul>\n<li><p><strong>视觉编码器 (Vision Encoder)</strong>：</p>\n<ul>\n<li><strong>模型选择</strong>：采用了一个预训练好且在整个Flamingo训练过程中保持<strong>冻结</strong>的Normalizer-Free ResNet (NFNet) 模型（具体为F6版本）。冻结视觉编码器可以保留其强大的、泛化的视觉特征提取能力，并节省大量计算资源。</li>\n<li><strong>预训练方式</strong>：该视觉编码器是在大规模图文对数据集上通过<strong>对比学习</strong>目标独立预训练的。这种训练方式旨在让模型学习到一种通用的视觉表示，使其能够理解图像内容并与文本描述对齐。</li>\n<li><strong>特征输出</strong>：对于<strong>图像输入</strong>，编码器输出其网络末端的一个二维空间特征图。这个特征图保留了图像的空间信息，随后被展平为一维的特征序列。对于<strong>视频输入</strong>，首先以1帧/秒的速率对视频进行采样，然后独立地对每一帧进行编码，得到一系列的帧特征。为了融入时序信息，模型会为这些帧特征添加一个可学习的<strong>时序嵌入</strong>，形成一个三维时空特征网格。最后，这个三维特征同样被展平为一维序列，准备送入下一模块。</li>\n</ul>\n</li>\n<li><p><strong>Perceiver Resampler (感知器重采样器)</strong>：</p>\n<ul>\n<li><strong>核心功能与目的</strong>：该模块是连接视觉编码器和冻结语言模型的关键桥梁。它的核心任务是接收来自视觉编码器的大量且<strong>可变长度</strong>的视觉特征（无论是来自高分辨率图像还是长视频），并将其压缩成<strong>少数固定数量</strong>的视觉令牌，在本研究中固定为64个。</li>\n<li><strong>解决的痛点</strong>：直接将高维度的视觉特征输入到大型语言模型中进行注意力计算，其计算成本会非常高昂。Perceiver Resampler通过显著减少视觉令牌的数量，极大地降低了后续视觉-文本交叉注意力（cross-attention）的计算复杂度，使得整个模型更加高效。</li>\n<li><strong>工作机制</strong>：其设计借鉴了Perceiver和DETR等模型的思想。它定义了一组预设数量的、可学习的<strong>潜在输入查询（latent input queries）</strong>。这些查询向量作为“信息汇总器”，通过一个Transformer结构中的交叉注意力机制，去“观察”和“查询”由视觉编码器生成的大量视觉特征。通过这个过程，它们将视觉特征中的核心信息“蒸馏”并吸收到自身中。最终，这些经过信息蒸馏的查询向量的输出，就构成了那一小组固定数量的视觉令牌。实验证明，这种方法比使用简单的多层感知机或标准的Transformer来进行特征池化效果更优。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"2-2-在视觉表征上对冻结语言模型进行条件化\"><a href=\"#2-2-在视觉表征上对冻结语言模型进行条件化\" class=\"headerlink\" title=\"2.2 在视觉表征上对冻结语言模型进行条件化\"></a>2.2 在视觉表征上对冻结语言模型进行条件化</h2><p>模型的文本生成能力由一个强大的、预训练好的<strong>冻结语言模型</strong>提供。为了让这个LM能够“看到”图像内容，需要将Perceiver Resampler产生的视觉令牌有效地融入其处理流程中。</p>\n<p><img src=\"/post/flamingo%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/file-20250705114307329.png\" alt></p>\n<ul>\n<li><p><strong>GATED XATTN-DENSE（门控交叉注意力-稠密连接）层</strong>：</p>\n<ul>\n<li><strong>非侵入式集成</strong>：为了保留LM强大的预训练知识并防止“灾难性遗忘”（即模型在学习新知识时忘记旧知识），Flamingo<strong>不直接微调LM的参数</strong>。相反，它在原始LM的各个预训练层之间，<strong>插入</strong>了若干个全新的、从零开始训练的模块，即GATED XATTN-DENSE层。</li>\n<li><strong>结构与功能</strong>：<ol>\n<li><strong>交叉注意力 (XATTN)</strong>：这是实现视觉与语言融合的核心。在这一层中，注意力机制的查询（Query, Q）来自于前一个冻结LM层的文本表征，而键（Key, K）和值（Value, V）则来自于Perceiver Resampler输出的视觉令牌。这使得在生成每一个文本词元时，模型都能够有针对性地“关注”视觉输入中的相关区域。</li>\n<li><strong>稠密连接 (DENSE)</strong>：交叉注意力层之后连接一个标准的前馈神经网络（Feed-Forward Network），进行进一步的特征转换。</li>\n<li><strong>门控机制 (GATED)</strong>：这是一个对训练稳定性和最终性能至关重要的设计。新添加模块的输出并不会直接与原始的文本表示相加。相反，它会经过一个<strong>tanh门控机制</strong>。该机制通过一个可学习的标量参数 <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.448ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewbox=\"0 -442 640 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D6FC\" d=\"M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z\"/></g></g></g></svg></mjx-container> 来控制新模块的输出贡献。这个 <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.448ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewbox=\"0 -442 640 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D6FC\" d=\"M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z\"/></g></g></g></svg></mjx-container> 被<strong>初始化为0</strong>。</li>\n</ol>\n</li>\n<li><strong>初始化优势</strong>：由于在初始化时 <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.186ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.596ex\" height=\"1.692ex\" role=\"img\" focusable=\"false\" viewbox=\"0 -666 2473.6 748\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D6FC\" d=\"M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z\"/></g><g data-mml-node=\"mo\" transform=\"translate(917.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"/></g><g data-mml-node=\"mn\" transform=\"translate(1973.6,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"/></g></g></g></svg></mjx-container>，所以 <code>tanh(α)</code> 也为0，导致整个新添加模块的输出在训练开始时为零。这意味着，在训练初期，整个Flamingo模型的输出与那个未经改动的、冻结的LM完全相同。这保证了训练的稳定启动，避免了随机初始化的新层对强大预训练模型的干扰。随着训练的进行，模型会逐渐学习调整 <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.448ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewbox=\"0 -442 640 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D6FC\" d=\"M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z\"/></g></g></g></svg></mjx-container> 的值，从而平滑地、自适应地将视觉信息融合进来。</li>\n</ul>\n</li>\n<li><p><strong>模型规模</strong>：研究团队基于Chinchilla系列语言模型构建了三种不同规模的Flamingo：Flamingo-3B, Flamingo-9B, 和 Flamingo-80B。在扩大模型尺寸时，主要是增加了冻结LM的参数量以及可训练的GATED XATTN-DENSE模块的数量，而视觉编码器和Perceiver Resampler的尺寸在不同规模的模型间保持不变。</p>\n</li>\n</ul>\n<h2 id=\"2-3-多视觉输入支持：逐图像-视频的注意力掩码\"><a href=\"#2-3-多视觉输入支持：逐图像-视频的注意力掩码\" class=\"headerlink\" title=\"2.3 多视觉输入支持：逐图像/视频的注意力掩码\"></a>2.3 多视觉输入支持：逐图像/视频的注意力掩码</h2><p>为了让模型能够处理包含多个视觉输入的提示（例如，在小样本学习场景下，提示中包含多个&lt;图像, 文本&gt;对），并正确地将文本与对应的视觉输入关联起来，Flamingo采用了一种精巧的<strong>注意力掩码策略</strong>。</p>\n<ul>\n<li><strong>工作机制</strong>：在进行文本到图像的交叉注意力计算时，模型采用了<strong>因果掩码（causal masking）</strong>。具体来说，当模型正在预测某个文本词元时，它的交叉注意力模块被限制为<strong>只能关注（attend to）在交错序列中紧邻于它之前的那个图像/视频所对应的视觉令牌</strong>。模型不能直接通过交叉注意力“回顾”更早出现的其他所有图像。</li>\n<li><strong>信息流的保持</strong>：尽管交叉注意力被限制在单个最近的图像上，但对先前所有图像的信息依赖性并不会丢失。这些信息是通过语言模型内部的<strong>自注意力机制</strong>来间接维持的。当模型处理完一个&lt;图像, 文本&gt;对后，视觉信息已经影响了生成的文本，这些文本作为历史信息存储在LM的状态中。在后续步骤里，LM可以通过自注意力机制访问和利用这些包含了早前视觉信息的状态。</li>\n<li><strong>核心优势</strong>：这种“单次只看一张图”的交叉注意力方案，不仅计算高效，更重要的是赋予了模型极佳的<strong>泛化能力</strong>。它使得模型可以无缝地处理任意数量的视觉输入，即使在训练时接触的图像数量有限（例如，训练时最多使用5张图），在推理时也能从多达32个图文对中获益。</li>\n</ul>\n<h2 id=\"2-4-在混合视觉与语言数据集上的训练\"><a href=\"#2-4-在混合视觉与语言数据集上的训练\" class=\"headerlink\" title=\"2.4 在混合视觉与语言数据集上的训练\"></a>2.4 在混合视觉与语言数据集上的训练</h2><p>Flamingo的小样本学习能力严重依赖于其独特的训练数据和策略。模型在一个混合了三种从网络上爬取的数据集上进行训练，未使用任何专为机器学习目的而人工标注的数据。</p>\n<ul>\n<li><p><strong>数据集构成</strong>：</p>\n<ol>\n<li><strong>M3W (MultiModal MassiveWeb)</strong>：这是一个包含约4300万个网页的<strong>交错图文数据集</strong>。通过解析网页的DOM树结构，将图像以<code>&lt;image&gt;</code>标签的形式插入到其在原文中相应位置的文本流中，从而构建出自然的、图文混排的训练样本。这是训练模型理解上下文和进行小样本学习的关键。</li>\n<li><strong>图文对数据集</strong>：这部分由两块组成，一是公开的ALIGN数据集（18亿图文对），二是团队自己收集的、描述更长更优质的LTIP数据集（3.12亿图文对）。</li>\n<li><strong>视频文本对数据集 (VTP)</strong>：一个包含2700万个短视频及其文本描述的数据集。</li>\n</ol>\n</li>\n<li><p><strong>语法对齐与多目标训练</strong>：</p>\n<ul>\n<li>为了统一训练格式，所有图文对和视频文本对数据都被处理成与M3W相似的语法，即在文本描述前后分别加上<code>&lt;image&gt;</code>和<code>&lt;EOC&gt;</code>（end of chunk）特殊标记。</li>\n<li>论文通过最小化给定视觉输入时每个数据集的文本期望负对数似然加权和来训练模型： <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -1.469ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"46.698ex\" height=\"4.07ex\" role=\"img\" focusable=\"false\" viewbox=\"0 -1149.5 20640.5 1799\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"munderover\"><g data-mml-node=\"mo\"><path data-c=\"2211\" d=\"M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z\"/></g><g data-mml-node=\"TeXAtom\" transform=\"translate(1089,477.1) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D440\" d=\"M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z\"/></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(1089,-285.4) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"/></g><g data-mml-node=\"mo\" transform=\"translate(878,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"/></g><g data-mml-node=\"mn\" transform=\"translate(1656,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"/></g></g></g><g data-mml-node=\"msub\" transform=\"translate(2830.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D706\" d=\"M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z\"/></g><g data-mml-node=\"TeXAtom\" transform=\"translate(616,-150) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"/></g></g></g><g data-mml-node=\"mo\" transform=\"translate(4339.3,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"/></g><g data-mml-node=\"msub\" transform=\"translate(4839.5,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D53C\" d=\"M12 666Q12 675 24 683H582Q590 680 593 672V588Q593 514 591 502T575 490Q567 490 563 495T555 517Q552 556 517 590Q486 623 445 634T340 648H282Q266 636 264 620T260 492V370H277Q329 375 358 391T404 439Q420 480 420 506Q420 529 436 529Q445 529 451 521Q455 517 455 361Q455 333 455 298T456 253Q456 217 453 207T437 197Q420 196 420 217Q420 240 406 270Q377 328 284 335H260V201Q261 174 261 134Q262 73 264 61T278 38Q281 36 282 35H331Q400 35 449 50Q571 93 602 179Q605 203 622 203Q629 203 634 197T640 183Q638 181 624 95T604 3L600 -1H24Q12 5 12 16Q12 35 51 35Q92 38 97 52Q102 60 102 341T97 632Q91 645 51 648Q12 648 12 666ZM137 341Q137 131 136 89T130 37Q129 36 129 35H235Q233 41 231 48L226 61V623L231 635L235 648H129Q132 641 133 638T135 603T137 517T137 341ZM557 603V648H504Q504 646 515 639Q527 634 542 619L557 603ZM420 317V397L406 383Q394 370 380 363L366 355Q373 350 382 346Q400 333 409 328L420 317ZM582 61L586 88Q585 88 582 83Q557 61 526 46L511 37L542 35H577Q577 36 578 39T580 49T582 61Z\"/></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(700,-176.7) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"/></g><g data-mml-node=\"mi\" transform=\"translate(389,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"/></g><g data-mml-node=\"mo\" transform=\"translate(961,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"/></g><g data-mml-node=\"mi\" transform=\"translate(1239,0)\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"/></g><g data-mml-node=\"mo\" transform=\"translate(1729,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"/></g><g data-mml-node=\"mo\" transform=\"translate(2118,0)\"><path data-c=\"223C\" d=\"M55 166Q55 241 101 304T222 367Q260 367 296 349T362 304T421 252T484 208T554 189Q616 189 655 236T694 338Q694 350 698 358T708 367Q722 367 722 334Q722 260 677 197T562 134H554Q517 134 481 152T414 196T355 248T292 293T223 311Q179 311 145 286Q109 257 96 218T80 156T69 133Q55 133 55 166Z\"/></g><g data-mml-node=\"msub\" transform=\"translate(2896,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"44\" d=\"M37 475Q19 475 19 487Q19 536 103 604T327 682H356Q386 683 408 683H419Q475 683 506 681T582 668T667 633Q766 571 766 450Q766 365 723 287T611 152T455 57T279 6Q248 1 160 0Q148 0 131 0T108 -1Q72 -1 72 11Q72 24 90 40T133 64L144 68L152 88Q247 328 272 587Q275 613 272 613Q272 613 269 613Q225 610 195 602T149 579T129 556T119 532Q118 530 116 525T113 518Q102 502 80 490T37 475ZM665 407Q665 596 412 613Q403 614 383 614Q370 614 370 612Q370 598 363 542T323 357T242 103L228 69H265Q391 73 481 119Q536 148 575 188T633 268T658 338T665 392V407Z\"/></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(804,-150) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"/></g></g></g></g></g><g data-mml-node=\"mrow\" transform=\"translate(8846.8,0)\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"5B\" d=\"M224 -649V1150H455V1099H275V-598H455V-649H224Z\"/></g><g data-mml-node=\"mo\" transform=\"translate(472,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"/></g><g data-mml-node=\"munderover\" transform=\"translate(1416.7,0)\"><g data-mml-node=\"mo\"><path data-c=\"2211\" d=\"M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z\"/></g><g data-mml-node=\"TeXAtom\" transform=\"translate(1089,477.1) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D43F\" d=\"M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z\"/></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(1089,-285.4) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"2113\" d=\"M345 104T349 104T361 95T369 80T352 59Q268 -20 206 -20Q170 -20 146 3T113 53T99 104L94 129Q94 130 79 116T48 86T28 70Q22 70 15 79T7 94Q7 98 12 103T58 147L91 179V185Q91 186 91 191T92 200Q92 282 128 400T223 612T336 705Q397 705 397 636V627Q397 453 194 233Q185 223 180 218T174 211T171 208T165 201L163 186Q159 142 159 123Q159 17 208 17Q228 17 253 30T293 56T335 94Q345 104 349 104ZM360 634Q360 655 354 661T336 668Q328 668 322 666T302 645T272 592Q252 547 229 467T192 330L179 273Q179 272 186 280T204 300T221 322Q327 453 355 590Q360 612 360 634Z\"/></g><g data-mml-node=\"mo\" transform=\"translate(417,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"/></g><g data-mml-node=\"mn\" transform=\"translate(1195,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"/></g></g></g><g data-mml-node=\"mi\" transform=\"translate(3920.9,0)\"><path data-c=\"6C\" d=\"M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z\"/><path data-c=\"6F\" d=\"M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z\" transform=\"translate(278,0)\"/><path data-c=\"67\" d=\"M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z\" transform=\"translate(778,0)\"/></g><g data-mml-node=\"mo\" transform=\"translate(5198.9,0)\"><path data-c=\"2061\" d=\"\"/></g><g data-mml-node=\"mi\" transform=\"translate(5365.5,0)\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"/></g><g data-mml-node=\"mrow\" transform=\"translate(6035.2,0)\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"/></g><g data-mml-node=\"msub\" transform=\"translate(389,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"/></g><g data-mml-node=\"TeXAtom\" transform=\"translate(523,-150) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"2113\" d=\"M345 104T349 104T361 95T369 80T352 59Q268 -20 206 -20Q170 -20 146 3T113 53T99 104L94 129Q94 130 79 116T48 86T28 70Q22 70 15 79T7 94Q7 98 12 103T58 147L91 179V185Q91 186 91 191T92 200Q92 282 128 400T223 612T336 705Q397 705 397 636V627Q397 453 194 233Q185 223 180 218T174 211T171 208T165 201L163 186Q159 142 159 123Q159 17 208 17Q228 17 253 30T293 56T335 94Q345 104 349 104ZM360 634Q360 655 354 661T336 668Q328 668 322 666T302 645T272 592Q252 547 229 467T192 330L179 273Q179 272 186 280T204 300T221 322Q327 453 355 590Q360 612 360 634Z\"/></g></g></g><g data-mml-node=\"mo\" transform=\"translate(1256.9,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"/></g><g data-mml-node=\"msub\" transform=\"translate(1534.9,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"/></g><g data-mml-node=\"TeXAtom\" transform=\"translate(523,-150) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"3C\" d=\"M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z\"/></g><g data-mml-node=\"mi\" transform=\"translate(778,0)\"><path data-c=\"2113\" d=\"M345 104T349 104T361 95T369 80T352 59Q268 -20 206 -20Q170 -20 146 3T113 53T99 104L94 129Q94 130 79 116T48 86T28 70Q22 70 15 79T7 94Q7 98 12 103T58 147L91 179V185Q91 186 91 191T92 200Q92 282 128 400T223 612T336 705Q397 705 397 636V627Q397 453 194 233Q185 223 180 218T174 211T171 208T165 201L163 186Q159 142 159 123Q159 17 208 17Q228 17 253 30T293 56T335 94Q345 104 349 104ZM360 634Q360 655 354 661T336 668Q328 668 322 666T302 645T272 592Q252 547 229 467T192 330L179 273Q179 272 186 280T204 300T221 322Q327 453 355 590Q360 612 360 634Z\"/></g></g></g><g data-mml-node=\"mo\" transform=\"translate(2952.9,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"/></g><g data-mml-node=\"msub\" transform=\"translate(3397.5,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"/></g><g data-mml-node=\"TeXAtom\" transform=\"translate(605,-150) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"2264\" d=\"M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z\"/></g><g data-mml-node=\"mi\" transform=\"translate(778,0)\"><path data-c=\"2113\" d=\"M345 104T349 104T361 95T369 80T352 59Q268 -20 206 -20Q170 -20 146 3T113 53T99 104L94 129Q94 130 79 116T48 86T28 70Q22 70 15 79T7 94Q7 98 12 103T58 147L91 179V185Q91 186 91 191T92 200Q92 282 128 400T223 612T336 705Q397 705 397 636V627Q397 453 194 233Q185 223 180 218T174 211T171 208T165 201L163 186Q159 142 159 123Q159 17 208 17Q228 17 253 30T293 56T335 94Q345 104 349 104ZM360 634Q360 655 354 661T336 668Q328 668 322 666T302 645T272 592Q252 547 229 467T192 330L179 273Q179 272 186 280T204 300T221 322Q327 453 355 590Q360 612 360 634Z\"/></g></g></g><g data-mml-node=\"mo\" transform=\"translate(4897.5,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"/></g></g><g data-mml-node=\"mo\" transform=\"translate(11321.7,0) translate(0 -0.5)\"><path data-c=\"5D\" d=\"M16 1099V1150H247V-649H16V-598H196V1099H16Z\"/></g></g></g></g></svg></mjx-container>, 其中<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.963ex\" height=\"1.464ex\" role=\"img\" focusable=\"false\" viewbox=\"0 -442 867.9 647\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"/></g><g data-mml-node=\"TeXAtom\" transform=\"translate(523,-150) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"2113\" d=\"M345 104T349 104T361 95T369 80T352 59Q268 -20 206 -20Q170 -20 146 3T113 53T99 104L94 129Q94 130 79 116T48 86T28 70Q22 70 15 79T7 94Q7 98 12 103T58 147L91 179V185Q91 186 91 191T92 200Q92 282 128 400T223 612T336 705Q397 705 397 636V627Q397 453 194 233Q185 223 180 218T174 211T171 208T165 201L163 186Q159 142 159 123Q159 17 208 17Q228 17 253 30T293 56T335 94Q345 104 349 104ZM360 634Q360 655 354 661T336 668Q328 668 322 666T302 645T272 592Q252 547 229 467T192 330L179 273Q179 272 186 280T204 300T221 322Q327 453 355 590Q360 612 360 634Z\"/></g></g></g></g></g></svg></mjx-container>是输入文本的第<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.045ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.943ex\" height=\"1.64ex\" role=\"img\" focusable=\"false\" viewbox=\"0 -705 417 725\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"2113\" d=\"M345 104T349 104T361 95T369 80T352 59Q268 -20 206 -20Q170 -20 146 3T113 53T99 104L94 129Q94 130 79 116T48 86T28 70Q22 70 15 79T7 94Q7 98 12 103T58 147L91 179V185Q91 186 91 191T92 200Q92 282 128 400T223 612T336 705Q397 705 397 636V627Q397 453 194 233Q185 223 180 218T174 211T171 208T165 201L163 186Q159 142 159 123Q159 17 208 17Q228 17 253 30T293 56T335 94Q345 104 349 104ZM360 634Q360 655 354 661T336 668Q328 668 322 666T302 645T272 592Q252 547 229 467T192 330L179 273Q179 272 186 280T204 300T221 322Q327 453 355 590Q360 612 360 634Z\"/></g></g></g></svg></mjx-container>个语言标记，<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.208ex\" height=\"1.464ex\" role=\"img\" focusable=\"false\" viewbox=\"0 -442 1418 647\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"/></g><g data-mml-node=\"TeXAtom\" transform=\"translate(523,-150) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"3C\" d=\"M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z\"/></g><g data-mml-node=\"mi\" transform=\"translate(778,0)\"><path data-c=\"2113\" d=\"M345 104T349 104T361 95T369 80T352 59Q268 -20 206 -20Q170 -20 146 3T113 53T99 104L94 129Q94 130 79 116T48 86T28 70Q22 70 15 79T7 94Q7 98 12 103T58 147L91 179V185Q91 186 91 191T92 200Q92 282 128 400T223 612T336 705Q397 705 397 636V627Q397 453 194 233Q185 223 180 218T174 211T171 208T165 201L163 186Q159 142 159 123Q159 17 208 17Q228 17 253 30T293 56T335 94Q345 104 349 104ZM360 634Q360 655 354 661T336 668Q328 668 322 666T302 645T272 592Q252 547 229 467T192 330L179 273Q179 272 186 280T204 300T221 322Q327 453 355 590Q360 612 360 634Z\"/></g></g></g></g></g></svg></mjx-container>是前面的标记集合，<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.56ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.394ex\" height=\"1.56ex\" role=\"img\" focusable=\"false\" viewbox=\"0 -442 1500 689.6\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"/></g><g data-mml-node=\"TeXAtom\" transform=\"translate(605,-150) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"2264\" d=\"M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z\"/></g><g data-mml-node=\"mi\" transform=\"translate(778,0)\"><path data-c=\"2113\" d=\"M345 104T349 104T361 95T369 80T352 59Q268 -20 206 -20Q170 -20 146 3T113 53T99 104L94 129Q94 130 79 116T48 86T28 70Q22 70 15 79T7 94Q7 98 12 103T58 147L91 179V185Q91 186 91 191T92 200Q92 282 128 400T223 612T336 705Q397 705 397 636V627Q397 453 194 233Q185 223 180 218T174 211T171 208T165 201L163 186Q159 142 159 123Q159 17 208 17Q228 17 253 30T293 56T335 94Q345 104 349 104ZM360 634Q360 655 354 661T336 668Q328 668 322 666T302 645T272 592Q252 547 229 467T192 330L179 273Q179 272 186 280T204 300T221 322Q327 453 355 590Q360 612 360 634Z\"/></g></g></g></g></g></svg></mjx-container>是交错序列中先于标记<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.963ex\" height=\"1.464ex\" role=\"img\" focusable=\"false\" viewbox=\"0 -442 867.9 647\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"/></g><g data-mml-node=\"TeXAtom\" transform=\"translate(523,-150) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"2113\" d=\"M345 104T349 104T361 95T369 80T352 59Q268 -20 206 -20Q170 -20 146 3T113 53T99 104L94 129Q94 130 79 116T48 86T28 70Q22 70 15 79T7 94Q7 98 12 103T58 147L91 179V185Q91 186 91 191T92 200Q92 282 128 400T223 612T336 705Q397 705 397 636V627Q397 453 194 233Q185 223 180 218T174 211T171 208T165 201L163 186Q159 142 159 123Q159 17 208 17Q228 17 253 30T293 56T335 94Q345 104 349 104ZM360 634Q360 655 354 661T336 668Q328 668 322 666T302 645T272 592Q252 547 229 467T192 330L179 273Q179 272 186 280T204 300T221 322Q327 453 355 590Q360 612 360 634Z\"/></g></g></g></g></g></svg></mjx-container>的图像/视频集合，<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.357ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.337ex\" height=\"1.902ex\" role=\"img\" focusable=\"false\" viewbox=\"0 -683 1474.8 840.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"44\" d=\"M37 475Q19 475 19 487Q19 536 103 604T327 682H356Q386 683 408 683H419Q475 683 506 681T582 668T667 633Q766 571 766 450Q766 365 723 287T611 152T455 57T279 6Q248 1 160 0Q148 0 131 0T108 -1Q72 -1 72 11Q72 24 90 40T133 64L144 68L152 88Q247 328 272 587Q275 613 272 613Q272 613 269 613Q225 610 195 602T149 579T129 556T119 532Q118 530 116 525T113 518Q102 502 80 490T37 475ZM665 407Q665 596 412 613Q403 614 383 614Q370 614 370 612Q370 598 363 542T323 357T242 103L228 69H265Q391 73 481 119Q536 148 575 188T633 268T658 338T665 392V407Z\"/></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(804,-150) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"/></g></g></g></g></g></svg></mjx-container>和<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.357ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.911ex\" height=\"1.927ex\" role=\"img\" focusable=\"false\" viewbox=\"0 -694 1286.8 851.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D706\" d=\"M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z\"/></g><g data-mml-node=\"TeXAtom\" transform=\"translate(616,-150) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"/></g></g></g></g></g></svg></mjx-container>分别表示第<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.986ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewbox=\"0 -442 878 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"/></g></g></g></svg></mjx-container>个数据集及其权重。调整每个数据集的权重<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.357ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.911ex\" height=\"1.927ex\" role=\"img\" focusable=\"false\" viewbox=\"0 -694 1286.8 851.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D706\" d=\"M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z\"/></g><g data-mml-node=\"TeXAtom\" transform=\"translate(616,-150) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"/></g></g></g></g></g></svg></mjx-container>是提升性能的关键。我论文对所有数据集的梯度进行累积，实验表明该方法优于“轮询”策略。</li>\n<li>在优化策略上，团队发现<strong>梯度累积</strong>的方式，即计算完所有数据集的梯度后再进行一次统一的参数更新，比轮流在单个数据集上训练的“round-robin”方法效果更佳。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"2-5-利用小样本上下文学习进行任务适配\"><a href=\"#2-5-利用小样本上下文学习进行任务适配\" class=\"headerlink\" title=\"2.5 利用小样本上下文学习进行任务适配\"></a>2.5 利用小样本上下文学习进行任务适配</h2><p>模型一旦训练完成，就可以通过上下文学习（in-context learning）的方式快速适应新的视觉任务，而无需任何参数更新。</p>\n<ul>\n<li><strong>提示构建 (Prompting)</strong>：为了解决一个新任务，用户需要构建一个多模态提示。这个提示由若干个“支持样本”和一个“查询样本”组成。例如，可以这样构建提示：<code>&lt;图片1&gt; &lt;答案1&gt; &lt;图片2&gt; &lt;答案2&gt; ... &lt;查询图片&gt;</code>。模型在看到这个提示后，会续写出针对查询图片的答案。</li>\n<li><strong>评估方式</strong>：<ul>\n<li>对于<strong>开放式任务</strong>（如VQA），使用<strong>集束搜索</strong>解码策略来生成最可能的自由文本答案。</li>\n<li>对于<strong>封闭式任务</strong>（如多项选择），模型会分别计算每个选项作为答案的<strong>对数似然概率（log-likelihood）</strong>，并选择概率最高的那个作为最终答案。</li>\n</ul>\n</li>\n<li><strong>零样本泛化</strong>：研究还探索了一种特殊的零样本设置，即在提示中只提供任务的纯文本示例（不附带图像），以测试模型是否能仅从文本描述中理解任务的格式和要求。</li>\n</ul>\n<h1 id=\"Experiments\"><a href=\"#Experiments\" class=\"headerlink\" title=\"Experiments\"></a>Experiments</h1><p>本部分旨在通过一系列广泛的实验来评估Flamingo模型的性能，核心目标是验证其在多样化且具有挑战性的任务上快速适应的能力。</p>\n<p><strong>实验设置与评估策略</strong></p>\n<ul>\n<li><p><strong>评测基准</strong>：为了全面评估模型，实验覆盖了16个当前流行的多模态基准数据集。这些数据集涵盖了图像和视频理解的多个方面，包括图像描述、视频描述、视觉问答、视频问答、视觉对话以及多项选择题等。</p>\n</li>\n<li><p><strong>开发集与留出集（Held-out Set）</strong>：为了保证评估的公正性和科学性，实验将这16个基准分为了两组：</p>\n<ol>\n<li><strong>开发集（DEV Set）</strong>：包含5个基准（COCO, OKVQA, VQAv2, MSVDQA, VATEX）。这组数据集在研究过程中被用来验证模型的设计决策和调整超参数。研究者承认，由于模型在开发阶段“看到”了这些任务，其在这些基准上的最终性能评估可能存在偏向性（即可能被高估），但这种做法在领域内是普遍的。</li>\n<li><strong>留出集</strong>：包含其余的11个基准。这组数据集在模型设计和超参数选择的整个过程中都未被使用。它们仅在最后阶段被用来评估模型的最终性能，从而为模型的小样本学习能力提供一个无偏的、更可信的估计。</li>\n</ol>\n</li>\n<li><p><strong>数据划分</strong>：为了在开发集上进行严谨的评估并避免数据泄露，每个开发集基准都被划分为四个子集：验证集的支持样本（用于开发阶段构建提示）、验证集的查询样本（用于开发阶段评估）、测试集的支持样本（用于最终报告构建提示）、测试集的查询样本（用于最终报告评估）。对于留出集，则只需要测试集的支持和查询样本。</p>\n</li>\n<li><p><strong>评估超参数</strong>：为了证明模型的通用性，所有评估用的超参数（如解码策略等）在全部16个基准上都保持固定。根据任务的性质（例如是生成式还是选择式），会采用四种预设的提示模板中的一种。</p>\n</li>\n</ul>\n<h2 id=\"3-1-小样本学习性能\"><a href=\"#3-1-小样本学习性能\" class=\"headerlink\" title=\"3.1 小样本学习性能\"></a>3.1 小样本学习性能</h2><p>这是实验的核心部分，旨在衡量模型在仅有少量标注样本的情况下学习新任务的能力。</p>\n<ul>\n<li><strong>与先前小样本方法的对比</strong>：实验结果表明，在所有16个评测基准上，Flamingo的性能都<strong>显著超越了</strong>以往所有已发表的零样本或小样本方法。这一成就仅需每个任务提供极少数（例如4个）的示例即可实现，充分展示了模型高效且实用的任务适应能力。</li>\n</ul>\n<p><img src=\"/post/flamingo%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/file-20250705120351372.png\" alt></p>\n<ul>\n<li><p><strong>与完全微调（Fine-tuned）方法的对比</strong>：更引人注目的是，Flamingo的性能不仅在小样本领域领先，甚至能与那些在成千上万、乃至数十万个任务专属标注数据上进行<strong>完全微调的当前最先进（SOTA）模型相媲美</strong>。在其中的6个任务上，Flamingo仅凭一个通用的、未经微调的模型和32个任务样本，就<strong>超越了</strong>这些经过大量数据微调的SOTA模型。</p>\n</li>\n<li><p><strong>泛化能力验证</strong>：模型在11个留出基准上的强劲表现，证实了其设计和训练方法的泛化能力。这表明模型的优异性能并非过拟合于开发集，而是具备广泛适用性的。</p>\n</li>\n<li><p><strong>规模效应分析（Scaling Analysis）</strong>：</p>\n<ul>\n<li><strong>模型参数规模</strong>：性能随着模型参数量的增加而稳步提升，即Flamingo-80B优于Flamingo-9B，后者又优于Flamingo-3B。这与在大型语言模型领域观察到的“规模法则”（Scaling Law）相一致，即更大的模型通常具备更强的学习能力。</li>\n<li><strong>样本数量（Number of Shots）</strong>：对于同一个模型，其性能随着在提示中提供的上下文样本（shots）数量的增加而提高。</li>\n<li><strong>协同效应</strong>：研究发现，最大的模型（Flamingo-80B）能更好地利用更多的上下文样本。这表明模型规模和上下文信息量之间存在协同效应，更大的模型能更有效地从示例中学习。</li>\n<li><strong>架构灵活性的体现</strong>：一个非常关键的发现是，尽管模型在训练阶段最多只接触过包含5张图像的序列，但在推理（评估）时，它却能有效利用多达32张图像或视频的上下文信息并持续提升性能。这有力地证明了Flamingo架构（特别是其逐图像的注意力掩码机制）的灵活性和卓越的泛化能力。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3-2-Flamingo作为预训练模型进行微调的性能\"><a href=\"#3-2-Flamingo作为预训练模型进行微调的性能\" class=\"headerlink\" title=\"3.2 Flamingo作为预训练模型进行微调的性能\"></a>3.2 Flamingo作为预训练模型进行微调的性能</h2><p>尽管小样本学习是核心焦点，本部分也探索了当有充足标注数据时，将Flamingo作为预训练模型进行传统微调的潜力。</p>\n<ul>\n<li><p><strong>微调方法</strong>：研究团队对最大规模的Flamingo模型，在有大量标注数据的任务上进行微调。微调过程采用了一个较短的训练周期和较小的学习率。一个关键的改动是，在微调期间<strong>解冻了视觉主干网络</strong>。这使得模型的视觉部分也能针对特定任务进行调整，例如适应更高分辨率的图像输入。</p>\n</li>\n<li><p><strong>微调结果</strong>：通过微调，模型的性能在之前小样本学习的基础上得到了进一步提升。在那些之前通过小样本学习未能达到SOTA的9个任务中，微调后的Flamingo在其中的5个任务上（VQAv2, VATEX, VizWiz, MSRVTTQA, HatefulMemes）<strong>刷新了最先进记录（SOTA）</strong>。</p>\n</li>\n</ul>\n<p><img src=\"/post/flamingo%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/file-20250705120713568.png\" alt></p>\n<h2 id=\"3-3-消融研究\"><a href=\"#3-3-消融研究\" class=\"headerlink\" title=\"3.3 消融研究\"></a>3.3 消融研究</h2><p>为了理解模型各个组件和设计选择的重要性，研究者进行了一系列消融实验。这些实验主要在较小的Flamingo-3B模型上进行，以节省计算成本。</p>\n<ul>\n<li><p><strong>训练数据组合的重要性</strong>：</p>\n<ul>\n<li>移除<strong>交错图文数据集</strong>会导致模型性能出现超过17%的灾难性下降，这证明了在自然混排的图文数据上进行训练对于培养小样本学习能力至关重要。</li>\n<li>移除<strong>传统的图文对数据集</strong>同样会使性能下降近10%，这表明交错数据和成对数据是互补的，两者都不可或缺。</li>\n<li>移除视频-文本数据集会对所有视频相关任务的性能产生负面影响。</li>\n</ul>\n</li>\n<li><p><strong>视觉条件化架构的关键设计</strong>：</p>\n<ul>\n<li><strong>门控机制</strong>：在融合视觉和文本信息时使用的<strong>tanh门控机制</strong>至关重要。移除这个机制不仅导致性能下降4.2%，还会引发训练过程的不稳定。</li>\n<li><strong>交叉注意力架构</strong>：实验证明，本文提出的<code>GATED XATTN-DENSE</code>架构优于其他可替代的方案，如vanilla交叉注意力或一些“嫁接”（grafting）方法。</li>\n</ul>\n</li>\n<li><p><strong>计算与性能的权衡</strong>：</p>\n<ul>\n<li><strong>交叉注意力频率</strong>：在语言模型的每一层之间都插入新的交叉注意力模块能获得最佳性能，但这会显著增加训练的参数量和时间复杂度。实验发现，<strong>每隔4层插入一个模块</strong>是一个极佳的权衡点，它能将训练速度提升66%，而整体性能仅有1.9%的微小下降。基于这个发现，更大的模型采用了这种稀疏插入策略以在硬件限制下实现最优配置。</li>\n<li><strong>Resampler架构</strong>：<code>Perceiver Resampler</code>在性能和速度上均优于使用普通MLP或Transformer作为重采样器的替代方案。</li>\n</ul>\n</li>\n<li><p><strong>视觉编码器的影响</strong>：使用一个强大的视觉编码器非常重要。团队自己预训练的NFNet-F6编码器显著优于公开的CLIP ViT-L/14模型，证明高质量的视觉特征是模型性能的基石。</p>\n</li>\n<li><p><strong>冻结语言模型的必要性</strong>：这是整个方法论中最关键的发现之一。</p>\n<ul>\n<li>如果<strong>从零开始训练</strong>语言模型部分，性能会暴跌12.9%。</li>\n<li>更重要的是，即便是<strong>微调（而非冻结）预训练好的语言模型</strong>，也会导致8%的显著性能下降。这清晰地揭示了“<strong>灾难性遗忘</strong>”现象：在适应新的多模态目标时，语言模型会忘记其预训练阶段学到的宝贵的、通用的语言知识。因此，<strong>冻结语言模型</strong>是保证性能的必要手段，是一种比将纯文本预训练数据混入多模态训练中更优的策略。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/post/flamingo%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/file-20250705121106522.png\" alt></p>\n<h1 id=\"Related-Work\"><a href=\"#Related-Work\" class=\"headerlink\" title=\"Related Work\"></a>Related Work</h1><p>本节将Flamingo模型置于现有研究的广阔背景之下，阐述其与相关工作的联系与区别，主要涵盖三个领域：语言建模与小样本适应、视觉与语言的交叉研究，以及网络规模的训练数据集。</p>\n<h2 id=\"1-语言建模与小样本适应\"><a href=\"#1-语言建模与小样本适应\" class=\"headerlink\" title=\"1. 语言建模与小样本适应\"></a>1. 语言建模与小样本适应</h2><ul>\n<li><p><strong>技术背景</strong>：近年来，基于Transformer架构的语言模型取得了巨大进步，“预训练-再适应”已成为标准范式。Flamingo正是构建在这一坚实基础之上，其核心语言模块采用了强大的<strong>Chinchilla 70B</strong>大型语言模型。</p>\n</li>\n<li><p><strong>模型适应技术的多样性</strong>：将预训练好的大型语言模型适配到新任务上有多种技术路径：</p>\n<ul>\n<li><strong>适配器模块（Adapter Modules）</strong>：在预训练模型的层与层之间插入一些小型的、可训练的神经网络模块，在适配新任务时只训练这些适配器，而保持主干模型冻结。</li>\n<li><strong>部分参数微调</strong>：只微调模型中一小部分的参数（例如，只微调偏置项 bias），在保持大部分参数不变的情况下实现任务适配。</li>\n<li><strong>提示优化（Prompt Optimization）</strong>：保持模型完全不变，而是通过梯度下降等方法来学习最优的、能够引导模型产生正确输出的输入提示。</li>\n<li><strong>上下文学习（In-context Learning）</strong>：这是<strong>Flamingo采用的思路</strong>，其灵感直接来源于GPT-3等模型。这种方法无需任何梯度更新或参数修改，仅通过在模型的输入中提供几个任务示例，就能引导模型在推理时执行新任务。</li>\n</ul>\n</li>\n<li><p><strong>Flamingo的选择与定位</strong>：相较于其他需要复杂梯度优化的方法，Flamingo选择了更为简洁的上下文学习路径。它避开了基于度量学习（metric learning，旨在学习一个好的样本间相似度函数）或元学习（meta-learning，即“学会如何学习”，旨在让模型能从少量数据中快速学习）等更为复杂的少样本学习框架，转而将纯文本领域的上下文学习成功地推广到了多模态领域。</p>\n</li>\n</ul>\n<h2 id=\"2-当语言与视觉相遇\"><a href=\"#2-当语言与视觉相遇\" class=\"headerlink\" title=\"2. 当语言与视觉相遇\"></a>2. 当语言与视觉相遇</h2><ul>\n<li><p><strong>BERT的深远影响</strong>：语言模型（尤其是BERT）的成功极大地启发了视觉语言领域的研究。大量V-L模型借鉴了BERT的架构，使用Transformer来融合视觉和文本特征。然而，这些模型与Flamingo的一个<strong>根本区别</strong>在于，它们大多<strong>需要在下游任务上进行微调</strong>才能获得良好性能，而Flamingo则专注于无需微调的小样本学习。</p>\n</li>\n<li><p><strong>对比学习模型</strong>：这是V-L领域的另一大分支（如CLIP）。这类模型通过对比学习来对齐图像和文本的表示，从而计算它们之间的相似度。虽然Flamingo的<strong>视觉编码器本身是使用对比学习预训练的</strong>，但Flamingo模型整体的功能远超于此。对比学习模型只能进行“打分”，无法生成自由形式的文本，而Flamingo的核心能力之一正是<strong>生成性</strong>。</p>\n</li>\n<li><p><strong>自回归视觉语言模型</strong>：Flamingo属于能够自回归生成文本的VLM家族。在它出现的同时期，也有其他一些工作探索了将多种视觉任务统一表述为文本生成问题的范式。</p>\n</li>\n<li><p><strong>基于冻结语言模型的研究趋势</strong>：为了防止在多模态训练中破坏大型语言模型预训练好的强大能力（即“灾难性遗忘”），近期的一系列工作开始探索<strong>冻结语言模型</strong>的方案。Flamingo正是这一思想的践行者和集大成者。</p>\n</li>\n<li><p><strong>Flamingo的核心创新</strong>：尽管存在上述种种相关工作，Flamingo的独特性和核心创新在于，它是首个能够处理<strong>任意交错（arbitrarily interleaved）的图像、视频和文本序列</strong>的语言模型。这与之前大多数只能处理单个图像/视频与文本对的模型相比，是一个质的飞跃，使其能够处理更复杂、更自然的真实世界多模态场景。</p>\n</li>\n</ul>\n<h2 id=\"3-网络规模的视觉与语言训练数据集\"><a href=\"#3-网络规模的视觉与语言训练数据集\" class=\"headerlink\" title=\"3. 网络规模的视觉与语言训练数据集\"></a>3. 网络规模的视觉与语言训练数据集</h2><ul>\n<li><strong>数据瓶颈</strong>：高质量、人工标注的视觉语言数据集（如COCO, VQA）规模通常在数万到数十万级别，获取成本高昂，这限制了模型的扩展性。</li>\n<li><strong>网络数据的利用</strong>：为了突破这一瓶颈，许多研究转向从互联网上自动爬取海量的、自然存在的图文对数据。</li>\n<li><strong>Flamingo的贡献</strong>：Flamingo不仅利用了这种大规模的图文对数据，还进一步证明了训练数据的<strong>形态</strong>至关重要。它的一个关键贡献是证明了<strong>在包含交错图文的完整网页上进行训练</strong>的巨大价值。这种将网页视为一个单一、连贯的多模态序列的训练方式，是其强大上下文学习能力的关键来源。</li>\n<li><strong>与同期工作的比较</strong>：同期的CM3模型也使用了网页数据进行训练。但两者目标不同：CM3旨在生成HTML标记语言，而Flamingo将任务简化为生成纯文本；在评估上，CM3更侧重于语言任务，而Flamingo的重点是验证在各类视觉任务上的小样本学习能力。</li>\n</ul>\n","feature":true,"text":"Flamingo 是一种能通过少量标注示例快速适应新任务的视觉语言模型。其架构创新在于连接预训练视觉和语言模型、处理图文交错序列及接收图像视频输入。经大规模多模态网络语料训练后，在视觉问答、字幕生成等任务上少样本学习表现优异，超越需大量数据微调的模型。...","permalink":"/post/flamingo论文精读","photos":[],"count_time":{"symbolsCount":"11k","symbolsTime":"10 mins."},"categories":[],"tags":[{"name":"多模态","slug":"多模态","count":4,"path":"api/tags/多模态.json"},{"name":"小样本","slug":"小样本","count":1,"path":"api/tags/小样本.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Introduction\"><span class=\"toc-text\">Introduction</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-%E6%A0%B8%E5%BF%83%E6%8C%91%E6%88%98%E4%B8%8E%E7%8E%B0%E6%9C%89%E6%96%B9%E6%B3%95%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7\"><span class=\"toc-text\">1. 核心挑战与现有方法的局限性</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-Flamingo%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8F%90%E5%87%BA%E4%B8%8E%E6%A0%B8%E5%BF%83%E8%83%BD%E5%8A%9B\"><span class=\"toc-text\">2. Flamingo模型的提出与核心能力</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%9A%E5%B0%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%83%BD%E5%8A%9B%E6%89%A9%E5%B1%95%E8%87%B3%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A2%86%E5%9F%9F\"><span class=\"toc-text\">3. 设计思想：将大语言模型的能力扩展至多模态领域</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#4-Flamingo%E7%9A%84%E6%9E%B6%E6%9E%84%E7%90%86%E5%BF%B5%E4%B8%8E%E5%85%B3%E9%94%AE%E7%BB%84%E4%BB%B6\"><span class=\"toc-text\">4. Flamingo的架构理念与关键组件</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#5-%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5%E7%9A%84%E5%85%B3%E9%94%AE%E6%80%A7\"><span class=\"toc-text\">5. 训练策略的关键性</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Approach\"><span class=\"toc-text\">Approach</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-1-%E8%A7%86%E8%A7%89%E5%A4%84%E7%90%86%E4%B8%8EPerceiver-Resampler%E6%A8%A1%E5%9D%97\"><span class=\"toc-text\">2.1 视觉处理与Perceiver Resampler模块</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-2-%E5%9C%A8%E8%A7%86%E8%A7%89%E8%A1%A8%E5%BE%81%E4%B8%8A%E5%AF%B9%E5%86%BB%E7%BB%93%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E6%9D%A1%E4%BB%B6%E5%8C%96\"><span class=\"toc-text\">2.2 在视觉表征上对冻结语言模型进行条件化</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-3-%E5%A4%9A%E8%A7%86%E8%A7%89%E8%BE%93%E5%85%A5%E6%94%AF%E6%8C%81%EF%BC%9A%E9%80%90%E5%9B%BE%E5%83%8F-%E8%A7%86%E9%A2%91%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%8E%A9%E7%A0%81\"><span class=\"toc-text\">2.3 多视觉输入支持：逐图像&#x2F;视频的注意力掩码</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-4-%E5%9C%A8%E6%B7%B7%E5%90%88%E8%A7%86%E8%A7%89%E4%B8%8E%E8%AF%AD%E8%A8%80%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E7%9A%84%E8%AE%AD%E7%BB%83\"><span class=\"toc-text\">2.4 在混合视觉与语言数据集上的训练</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-5-%E5%88%A9%E7%94%A8%E5%B0%8F%E6%A0%B7%E6%9C%AC%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0%E8%BF%9B%E8%A1%8C%E4%BB%BB%E5%8A%A1%E9%80%82%E9%85%8D\"><span class=\"toc-text\">2.5 利用小样本上下文学习进行任务适配</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Experiments\"><span class=\"toc-text\">Experiments</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-1-%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0%E6%80%A7%E8%83%BD\"><span class=\"toc-text\">3.1 小样本学习性能</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-2-Flamingo%E4%BD%9C%E4%B8%BA%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E5%BE%AE%E8%B0%83%E7%9A%84%E6%80%A7%E8%83%BD\"><span class=\"toc-text\">3.2 Flamingo作为预训练模型进行微调的性能</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-3-%E6%B6%88%E8%9E%8D%E7%A0%94%E7%A9%B6\"><span class=\"toc-text\">3.3 消融研究</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Related-Work\"><span class=\"toc-text\">Related Work</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-%E8%AF%AD%E8%A8%80%E5%BB%BA%E6%A8%A1%E4%B8%8E%E5%B0%8F%E6%A0%B7%E6%9C%AC%E9%80%82%E5%BA%94\"><span class=\"toc-text\">1. 语言建模与小样本适应</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-%E5%BD%93%E8%AF%AD%E8%A8%80%E4%B8%8E%E8%A7%86%E8%A7%89%E7%9B%B8%E9%81%87\"><span class=\"toc-text\">2. 当语言与视觉相遇</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-%E7%BD%91%E7%BB%9C%E8%A7%84%E6%A8%A1%E7%9A%84%E8%A7%86%E8%A7%89%E4%B8%8E%E8%AF%AD%E8%A8%80%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86\"><span class=\"toc-text\">3. 网络规模的视觉与语言训练数据集</span></a></li></ol></li></ol>","author":{"name":"犬夜叉","slug":"blog-author","avatar":"https://i.imgur.com/CrgPA5H_d.png?maxwidth=520&shape=thumb&fidelity=high","link":"/","description":"一位喜欢犬夜叉的多模态大模型研究生","socials":{"github":"https://github.com/ziyi-wang2003","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/qq_62954485?spm=1000.2115.3001.5343","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{},"next_post":{"title":"ALBEF论文精读","uid":"5cac6105e8bc407ec91f6896ed602917","slug":"ALBEF论文精读","date":"2025-07-03T03:20:45.000Z","updated":"2025-07-05T02:30:25.770Z","comments":true,"path":"api/articles/ALBEF论文精读.json","keywords":null,"cover":"https://i.imgur.com/GDGylHi_d.png?maxwidth=520&shape=thumb&fidelity=high","text":"论文提出 ALBEF 框架，通过对比损失对齐图文表示，结合动量蒸馏处理噪声数据，在多任务上性能优于 SOTA。...","permalink":"/post/ALBEF论文精读","photos":[],"count_time":{"symbolsCount":"8.3k","symbolsTime":"8 mins."},"categories":[],"tags":[{"name":"多模态","slug":"多模态","count":4,"path":"api/tags/多模态.json"},{"name":"VLP","slug":"VLP","count":2,"path":"api/tags/VLP.json"}],"author":{"name":"犬夜叉","slug":"blog-author","avatar":"https://i.imgur.com/CrgPA5H_d.png?maxwidth=520&shape=thumb&fidelity=high","link":"/","description":"一位喜欢犬夜叉的多模态大模型研究生","socials":{"github":"https://github.com/ziyi-wang2003","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/qq_62954485?spm=1000.2115.3001.5343","juejin":"","customs":{}}},"feature":true}}