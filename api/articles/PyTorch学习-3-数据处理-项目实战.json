{"title":"PyTorch学习-3-数据处理&项目实战","uid":"524ccad428f7700ee84d802ab1c86ad8","slug":"PyTorch学习-3-数据处理-项目实战","date":"2025-07-08T05:09:24.000Z","updated":"2025-07-08T06:00:11.038Z","comments":true,"path":"api/articles/PyTorch学习-3-数据处理-项目实战.json","keywords":null,"cover":[],"content":"<h3 id=\"PyTorch学习-3-数据处理-项目实战\"><a href=\"#PyTorch学习-3-数据处理-项目实战\" class=\"headerlink\" title=\"PyTorch学习-3-数据处理-项目实战\"></a><strong>PyTorch学习-3-数据处理-项目实战</strong></h3><h3 id=\"模块-6：高效数据加载-Dataset-amp-DataLoader\"><a href=\"#模块-6：高效数据加载-Dataset-amp-DataLoader\" class=\"headerlink\" title=\"模块 6：高效数据加载 (Dataset & DataLoader)\"></a><strong>模块 6：高效数据加载 (<code>Dataset</code> &amp; <code>DataLoader</code>)</strong></h3><h4 id=\"6-1-为什么需要它们？\"><a href=\"#6-1-为什么需要它们？\" class=\"headerlink\" title=\"6.1 为什么需要它们？\"></a><strong>6.1 为什么需要它们？</strong></h4><p>想象一下，你有一个包含 50,000 张高清图像的数据集，总大小可能达到几十甚至上百 GB。你该如何训练你的模型？</p>\n<ul>\n<li><strong>一次性全部加载到内存？</strong> 这显然是不可行的。绝大多数情况下，你的内存（RAM 或 GPU VRAM）都无法容纳整个数据集。</li>\n<li><strong>手动编写循环，一张一张读取？</strong> 这会非常慢，因为磁盘 I/O 是一个瓶颈。更重要的是，你还需要自己处理：<ul>\n<li><strong>预处理 (Preprocessing):</strong> 每张图片都需要被转换成张量，可能还需要裁剪、归一化等操作。</li>\n<li><strong>批处理 (Batching):</strong> 现代 GPU 擅长并行计算，一次处理一批数据（例如 64 张图片）远比一张一张处理要高效得多。你需要手动将数据组合成批次。</li>\n<li><strong>打乱 (Shuffling):</strong> 为了让模型训练更稳定、泛化能力更强，每个 epoch 开始前都应该打乱数据顺序，防止模型学到数据的排列顺序。</li>\n<li><strong>并行加载 (Parallel Loading):</strong> 当 GPU 正在处理当前批次的数据时，CPU 应该已经在后台准备下一个批次了，以最大限度地减少 GPU 的等待时间。</li>\n</ul>\n</li>\n</ul>\n<p>PyTorch 提供了 <code>Dataset</code> 和 <code>DataLoader</code> 这对组合，优雅地解决了所有这些问题。</p>\n<ul>\n<li><code>Dataset</code>：负责<strong>定义数据集的来源和单一样本的获取方式</strong>。它只关心“总共有多少数据？”和“如何获取第 i 个数据？”。</li>\n<li><code>DataLoader</code>：负责<strong>从 <code>Dataset</code> 中取出数据，并以我们期望的方式（如批处理、打乱、并行加载）提供给模型</strong>。</li>\n</ul>\n<h4 id=\"6-2-torch-utils-data-Dataset-数据集的“蓝图”\"><a href=\"#6-2-torch-utils-data-Dataset-数据集的“蓝图”\" class=\"headerlink\" title=\"6.2 torch.utils.data.Dataset - 数据集的“蓝图”\"></a><strong>6.2 <code>torch.utils.data.Dataset</code> - 数据集的“蓝图”</strong></h4><p><code>Dataset</code> 是一个抽象类。要创建自己的数据集，你需要继承它，并重写两个核心的“魔法”方法：</p>\n<ol>\n<li><code>__len__(self)</code>: 应该返回数据集的总大小。<code>DataLoader</code> 需要这个信息来知道总共有多少样本。</li>\n<li><code>__getitem__(self, idx)</code>: 应该根据给定的索引 <code>idx</code>，返回<strong>一个</strong>数据样本。这是 <code>Dataset</code> 的核心，定义了如何从源（如文件、数据库）加载、预处理并返回单个数据点（通常是一个数据和标签的元组）。</li>\n</ol>\n<p><strong>代码示例：创建一个自定义的简单数据集</strong></p>\n<p>假设我们有一个 CSV 文件，内容是学生的“学习小时数”、“睡眠小时数”和“是否通过考试”。我们将为它创建一个 <code>Dataset</code>。</p>\n<pre class=\"line-numbers language-lang-python\"><code class=\"language-lang-python\">import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\n\n# 假设我们有这样的数据\n# 我们用 numpy 数组模拟，实际中可能是从文件中读取\ndata = np.array([\n    [8, 7, 1],  # [study_hours, sleep_hours, passed]\n    [5, 6, 0],\n    [2, 8, 0],\n    [9, 8, 1],\n    [4, 5, 0],\n    [7, 7, 1]\n])\n\nclass StudentDataset(Dataset):\n    def __init__(self, data):\n        # 在 __init__ 中，我们通常进行一次性的设置，比如加载数据\n        # 这里我们将数据源存储为类的属性\n        self.data = data\n        # 将特征 (X) 和标签 (y) 分开\n        self.X = torch.from_numpy(self.data[:, :-1]).float()\n        self.y = torch.from_numpy(self.data[:, -1]).float()\n        self.n_samples = self.data.shape[0]\n\n    def __getitem__(self, index):\n        # 这个方法根据索引返回一个样本\n        # DataLoader 会在后台调用这个方法来获取数据\n        return self.X[index], self.y[index]\n\n    def __len__(self):\n        # 这个方法返回数据集的总长度\n        return self.n_samples\n\n# 实例化我们的数据集\nstudent_dataset = StudentDataset(data)\n\n# 测试一下\nfirst_sample_features, first_sample_label = student_dataset[0]\nprint(f\"第一个样本的特征: {first_sample_features}\")\nprint(f\"第一个样本的标签: {first_sample_label}\")\nprint(f\"数据集总长度: {len(student_dataset)}\")\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<pre><code>第一个样本的特征: tensor([8., 7.])\n第一个样本的标签: 1.0\n数据集总长度: 6\n</code></pre><h4 id=\"6-3-torch-utils-data-DataLoader-智能的“数据搬运工”\"><a href=\"#6-3-torch-utils-data-DataLoader-智能的“数据搬运工”\" class=\"headerlink\" title=\"6.3 torch.utils.data.DataLoader - 智能的“数据搬运工”\"></a><strong>6.3 <code>torch.utils.data.DataLoader</code> - 智能的“数据搬运工”</strong></h4><p><code>DataLoader</code> 将 <code>Dataset</code> 包装成一个方便的 Python 可迭代对象。你可以在一个 <code>for</code> 循环中轻松地遍历它，每次迭代都会得到一个批次的数据。</p>\n<p><strong>核心参数</strong>:</p>\n<ul>\n<li><code>dataset</code>: 你实例化的 <code>Dataset</code> 对象。</li>\n<li><code>batch_size</code> (int, default=1): 每个批次包含的样本数量。</li>\n<li><code>shuffle</code> (bool, default=False): 是否在每个 epoch 开始时打乱数据。在训练时通常设置为 <code>True</code>，在评估时设置为 <code>False</code>。</li>\n<li><code>num_workers</code> (int, default=0): 使用多少个子进程来预加载数据。<code>0</code> 表示在主进程中加载数据。设置为大于 <code>0</code> 的整数（如 4, 8）可以极大地加速数据加载，因为它利用了多核 CPU 在后台准备数据，让 GPU 不用等待。这是提升训练效率的关键参数。</li>\n</ul>\n<p><strong>代码示例：使用 <code>DataLoader</code></strong></p>\n<pre class=\"line-numbers language-lang-python\"><code class=\"language-lang-python\"># 将我们创建的 Dataset 包装进 DataLoader\n# 设置批次大小为 2，并且打乱数据\ndata_loader = DataLoader(dataset=student_dataset, batch_size=2, shuffle=True, num_workers=0)\n\n# 模拟一个 epoch 的训练过程\nprint(\"\\n--- 遍历 DataLoader ---\")\nfor epoch in range(1): # 假设只训练一个 epoch\n    print(f\"Epoch {epoch+1}:\")\n    for i, (features, labels) in enumerate(data_loader):\n        # 在这里执行你的训练五步法\n        print(f\"  Batch {i+1}:\")\n        print(f\"    特征的形状: {features.shape}\") # torch.Size([2, 2]) -> [batch_size, num_features]\n        print(f\"    标签的形状: {labels.shape}\")   # torch.Size([2]) -> [batch_size]\n        # 注意标签需要调整形状以匹配模型输出\n        # view方法用于改变张量的形状，这里-1表示该维度的大小由其他维度的大小和张量元素总数自动推断得出，1表示新形状的第二个维度大小为 1 。\n        #这里是将获得的 [a,b] 转换为 [[a],[b]]\n        labels = labels.view(-1, 1)\n        print(f\"    调整后标签的形状: {labels.shape}\") # torch.Size([2, 1])\n        # ... optimizer.zero_grad(), model(features), etc.\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<pre><code>--- 遍历 DataLoader ---\nEpoch 1:\n  Batch 1:\n    特征的形状: torch.Size([2, 2])\n    标签的形状: torch.Size([2])\n    调整后标签的形状: torch.Size([2, 1])\n  Batch 2:\n    特征的形状: torch.Size([2, 2])\n    标签的形状: torch.Size([2])\n    调整后标签的形状: torch.Size([2, 1])\n  Batch 3:\n    特征的形状: torch.Size([2, 2])\n    标签的形状: torch.Size([2])\n    调整后标签的形状: torch.Size([2, 1])\n</code></pre><h4 id=\"6-4-torchvision-计算机视觉的“快餐店”\"><a href=\"#6-4-torchvision-计算机视觉的“快餐店”\" class=\"headerlink\" title=\"6.4 torchvision - 计算机视觉的“快餐店”\"></a><strong>6.4 <code>torchvision</code> - 计算机视觉的“快餐店”</strong></h4><p>对于常见的计算机视觉任务，你甚至不需要自己写 <code>Dataset</code>。<code>torchvision</code> 包提供了：</p>\n<ul>\n<li><strong><code>torchvision.datasets</code></strong>: 包含许多经典数据集的 <code>Dataset</code> 实现，如 <code>MNIST</code>, <code>CIFAR10</code>, <code>ImageNet</code>。你只需一行代码就可以下载和加载它们。</li>\n<li><strong><code>torchvision.transforms</code></strong>: 包含一系列常用的图像预处理操作，如调整大小、裁剪、旋转、转换为张量、归一化等。</li>\n</ul>\n<p><strong><code>transforms.Compose</code></strong> 是一个非常重要的工具，它可以将多个变换操作串联起来。</p>\n<p><strong>代码示例：加载带变换的 MNIST 数据集</strong></p>\n<pre class=\"line-numbers language-lang-python\"><code class=\"language-lang-python\">import torchvision\nimport torchvision.transforms as transforms\n\n# 定义一系列变换\n# 1. ToTensor(): 将 PIL.Image 或 numpy.ndarray 转换为 torch.FloatTensor，\n#    并且将像素值从 [0, 255] 缩放到 [0.0, 1.0]。\n# 2. Normalize(mean, std): 对张量进行归一化。output = (input - mean) / std。\n#    这里的 mean 和 std 是 MNIST 数据集在所有像素上的均值和标准差。\n#    归一化有助于模型更快地收敛。\ntransform_pipeline = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,)) # MNIST是单通道，所以mean和std都只有一个值\n])\n\n# 加载训练集\ntrain_dataset = torchvision.datasets.MNIST(root='./data', \n                                           train=True, \n                                           transform=transform_pipeline, \n                                           download=True)\n\n# 加载测试集\ntest_dataset = torchvision.datasets.MNIST(root='./data', \n                                          train=False, \n                                          transform=transform_pipeline)\n\n# 创建 DataLoader\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n\nprint(f\"\\nMNIST 训练集大小: {len(train_dataset)}\")\nprint(f\"MNIST 测试集大小: {len(test_dataset)}\")\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<hr>\n<h3 id=\"模块-7：经典模型实战\"><a href=\"#模块-7：经典模型实战\" class=\"headerlink\" title=\"模块 7：经典模型实战\"></a><strong>模块 7：经典模型实战</strong></h3><p>现在，让我们把所有知识融会贯通，完成两个端到端的项目。</p>\n<h4 id=\"7-1-计算机视觉-CV-在-MNIST-上实现-LeNet-5\"><a href=\"#7-1-计算机视觉-CV-在-MNIST-上实现-LeNet-5\" class=\"headerlink\" title=\"7.1 计算机视觉 (CV): 在 MNIST 上实现 LeNet-5\"></a><strong>7.1 计算机视觉 (CV): 在 MNIST 上实现 LeNet-5</strong></h4><p>LeNet-5 是由 Yann LeCun 在 1998 年提出的，是早期最成功的卷积神经网络之一，为现代 CNN 奠定了基础。我们将用 PyTorch 复现它，来解决手写数字识别问题。</p>\n<p><strong>A. 完整流程规划</strong></p>\n<ol>\n<li><strong>准备数据</strong>: 使用 <code>torchvision</code> 加载 MNIST 数据集，并创建 <code>DataLoader</code>。</li>\n<li><strong>定义模型</strong>: 创建一个 <code>LeNet5</code> 类，继承 <code>nn.Module</code>，并按照 LeNet-5 的结构搭建网络。</li>\n<li><strong>实例化</strong>: 创建模型、损失函数 (<code>CrossEntropyLoss</code>) 和优化器 (<code>Adam</code>) 的实例。</li>\n<li><strong>训练循环</strong>: 编写 <code>for</code> 循环，遍历 epochs 和 <code>train_loader</code>，执行“训练五步法”。</li>\n<li><strong>评估循环</strong>: 编写评估函数，在 <code>test_loader</code> 上计算模型的准确率和损失。</li>\n<li><strong>可视化</strong>: 绘制训练过程中的损失变化曲线，并展示一些模型的预测结果。</li>\n</ol>\n<p><strong>B. 代码实现</strong></p>\n<pre class=\"line-numbers language-lang-python\"><code class=\"language-lang-python\">import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# --- 1. 超参数与设备 ---\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nBATCH_SIZE = 64\nLEARNING_RATE = 0.001\nEPOCHS = 10\n\n# --- 2. 准备数据 ---\ntransform = transforms.Compose([\n    transforms.ToTensor(),  # 将图像数据转换为张量，并将像素值归一化到0到1内\n    transforms.Normalize((0.1307,), (0.3081,))  # 对已经转换为张量的图像数据进行归一化处理，分别是均值和标准差\n])\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\ntest_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform)\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n\n# --- 3. 定义 LeNet-5 模型 ---\nclass LeNet5(nn.Module):\n    def __init__(self):\n        super(LeNet5, self).__init__()\n        # LeNet-5 结构\n        # 输入: 1x28x28\n        # C1: 6个5x5卷积核, 输出 6x28x28 (padding=2)\n        # S2: 2x2最大池化, 输出 6x14x14\n        # C3: 16个5x5卷积核, 输出 16x10x10\n        # S4: 2x2最大池化, 输出 16x5x5\n        # C5(FC1): 全连接层, 16*5*5 -> 120\n        # FC2: 全连接层, 120 -> 84\n        # 输出: 84 -> 10\n        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2) # 保持尺寸不变\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5) # 展平\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n# --- 4. 实例化 ---\nmodel = LeNet5().to(DEVICE)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n# --- 5. 训练与评估循环 ---\ntrain_losses = []\ntest_losses = []\ntest_accuracies = []\n\nfor epoch in range(EPOCHS):\n    # 训练\n    model.train()\n    running_loss = 0.0\n    for i, (images, labels) in enumerate(train_loader):\n        images, labels = images.to(DEVICE), labels.to(DEVICE)\n\n        # 训练五步法\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    train_losses.append(running_loss / len(train_loader))\n\n    # 评估\n    model.eval()\n    correct = 0\n    total = 0\n    test_loss = 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            test_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    test_accuracies.append(accuracy)\n    test_losses.append(test_loss / len(test_loader))\n\n    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}, Test Accuracy: {accuracy:.2f}%')\n\nprint('Finished Training')\n\n# --- 6. 结果可视化 ---\n\n# 6.1 绘制损失和准确率曲线\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Training Loss')\nplt.plot(test_losses, label='Test Loss')\nplt.title('Loss over epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(test_accuracies, label='Test Accuracy', color='orange')\nplt.title('Accuracy over epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.legend()\nplt.show()\n\n# 6.2 可视化部分预测结果\ndef imshow(img):\n    img = img / 2 + 0.5 # 反归一化\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.axis('off')\n\n# 获取一个批次的测试数据\ndataiter = iter(test_loader)\nimages, labels = next(dataiter)\nimages, labels = images.to(DEVICE), labels.to(DEVICE)\n\n# 进行预测\noutputs = model(images)\n_, predicted = torch.max(outputs, 1)\n\n# 显示图像和预测结果\nprint('真实标签: ', ' '.join(f'{labels[j].item()}' for j in range(8)))\nprint('预测结果: ', ' '.join(f'{predicted[j].item()}' for j in range(8)))\n\n# 反归一化以正确显示\ninv_normalize = transforms.Normalize(\n   mean=[-0.1307/0.3081],\n   std=[1/0.3081]\n)\nimages_to_show = torch.stack([inv_normalize(img) for img in images[:8].cpu()])\n\nplt.figure(figsize=(10, 4))\nimshow(torchvision.utils.make_grid(images_to_show))\nplt.show()\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>训练结果：</strong></p>\n<pre><code>Epoch [1/10], Train Loss: 0.2482, Test Loss: 0.0717, Test Accuracy: 97.75%\nEpoch [2/10], Train Loss: 0.0670, Test Loss: 0.0474, Test Accuracy: 98.47%\nEpoch [3/10], Train Loss: 0.0492, Test Loss: 0.0455, Test Accuracy: 98.54%\nEpoch [4/10], Train Loss: 0.0385, Test Loss: 0.0363, Test Accuracy: 98.86%\nEpoch [5/10], Train Loss: 0.0305, Test Loss: 0.0348, Test Accuracy: 98.84%\nEpoch [6/10], Train Loss: 0.0264, Test Loss: 0.0435, Test Accuracy: 98.73%\nEpoch [7/10], Train Loss: 0.0222, Test Loss: 0.0382, Test Accuracy: 98.81%\nEpoch [8/10], Train Loss: 0.0208, Test Loss: 0.0304, Test Accuracy: 99.11%\nEpoch [9/10], Train Loss: 0.0166, Test Loss: 0.0335, Test Accuracy: 98.94%\nEpoch [10/10], Train Loss: 0.0154, Test Loss: 0.0402, Test Accuracy: 98.82%\nFinished Training\n</code></pre><p><img src=\"/post/PyTorch%E5%AD%A6%E4%B9%A0-3-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/file-20250708135017475.png\" alt><br><img src=\"/post/PyTorch%E5%AD%A6%E4%B9%A0-3-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/file-20250708135046524.png\" alt></p>\n","text":"PyTorch学习-3-数据处理-项目实战模块 6：高效数据加载 (Dataset & DataLoader)6.1 为什么需要它们？想象一下，你有一个包含 5...","permalink":"/post/PyTorch学习-3-数据处理-项目实战","photos":[],"count_time":{"symbolsCount":"11k","symbolsTime":"10 mins."},"categories":[{"name":"python语法学习","slug":"python语法学习","count":5,"path":"api/categories/python语法学习.json"}],"tags":[{"name":"PyTorch","slug":"PyTorch","count":3,"path":"api/tags/PyTorch.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#PyTorch%E5%AD%A6%E4%B9%A0-3-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98\"><span class=\"toc-text\">PyTorch学习-3-数据处理-项目实战</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9D%97-6%EF%BC%9A%E9%AB%98%E6%95%88%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD-Dataset-amp-DataLoader\"><span class=\"toc-text\">模块 6：高效数据加载 (Dataset &amp; DataLoader)</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#6-1-%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%AE%83%E4%BB%AC%EF%BC%9F\"><span class=\"toc-text\">6.1 为什么需要它们？</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#6-2-torch-utils-data-Dataset-%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E2%80%9C%E8%93%9D%E5%9B%BE%E2%80%9D\"><span class=\"toc-text\">6.2 torch.utils.data.Dataset - 数据集的“蓝图”</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#6-3-torch-utils-data-DataLoader-%E6%99%BA%E8%83%BD%E7%9A%84%E2%80%9C%E6%95%B0%E6%8D%AE%E6%90%AC%E8%BF%90%E5%B7%A5%E2%80%9D\"><span class=\"toc-text\">6.3 torch.utils.data.DataLoader - 智能的“数据搬运工”</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#6-4-torchvision-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9A%84%E2%80%9C%E5%BF%AB%E9%A4%90%E5%BA%97%E2%80%9D\"><span class=\"toc-text\">6.4 torchvision - 计算机视觉的“快餐店”</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9D%97-7%EF%BC%9A%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%98\"><span class=\"toc-text\">模块 7：经典模型实战</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#7-1-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-CV-%E5%9C%A8-MNIST-%E4%B8%8A%E5%AE%9E%E7%8E%B0-LeNet-5\"><span class=\"toc-text\">7.1 计算机视觉 (CV): 在 MNIST 上实现 LeNet-5</span></a></li></ol></li></ol>","author":{"name":"犬夜叉","slug":"blog-author","avatar":"https://i.imgur.com/CrgPA5H_d.png?maxwidth=520&shape=thumb&fidelity=high","link":"/","description":"一位喜欢犬夜叉的多模态大模型研究生","socials":{"github":"https://github.com/ziyi-wang2003","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/qq_62954485?spm=1000.2115.3001.5343","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"ALBEF论文精读","uid":"5cac6105e8bc407ec91f6896ed602917","slug":"ALBEF论文精读","date":"2025-07-03T03:20:45.000Z","updated":"2025-07-07T06:29:20.677Z","comments":true,"path":"api/articles/ALBEF论文精读.json","keywords":null,"cover":"https://i.imgur.com/GDGylHi_d.png?maxwidth=520&shape=thumb&fidelity=high","text":"论文提出 ALBEF 框架，通过对比损失对齐图文表示，结合动量蒸馏处理噪声数据，在多任务上性能优于 SOTA。...","permalink":"/post/ALBEF论文精读","photos":[],"count_time":{"symbolsCount":"8.3k","symbolsTime":"8 mins."},"categories":[{"name":"论文精读","slug":"论文精读","count":6,"path":"api/categories/论文精读.json"}],"tags":[{"name":"多模态","slug":"多模态","count":5,"path":"api/tags/多模态.json"},{"name":"VLP","slug":"VLP","count":2,"path":"api/tags/VLP.json"}],"author":{"name":"犬夜叉","slug":"blog-author","avatar":"https://i.imgur.com/CrgPA5H_d.png?maxwidth=520&shape=thumb&fidelity=high","link":"/","description":"一位喜欢犬夜叉的多模态大模型研究生","socials":{"github":"https://github.com/ziyi-wang2003","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/qq_62954485?spm=1000.2115.3001.5343","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"PyTorch学习-2-神经网络核心","uid":"d970942a0c3301df824e3c1c77149df6","slug":"PyTorch学习-2-神经网络核心","date":"2025-07-08T01:46:23.000Z","updated":"2025-07-08T06:05:08.835Z","comments":true,"path":"api/articles/PyTorch学习-2-神经网络核心.json","keywords":null,"cover":null,"text":"PyTorch 学习笔记 - 阶段二：神经网络的核心在前面的章节中，我们已经熟悉了 PyTorch 的基本数据结构——张量（Tensor），以及如何在它们之上执...","permalink":"/post/PyTorch学习-2-神经网络核心","photos":[],"count_time":{"symbolsCount":"17k","symbolsTime":"15 mins."},"categories":[{"name":"python语法学习","slug":"python语法学习","count":5,"path":"api/categories/python语法学习.json"}],"tags":[{"name":"PyTorch","slug":"PyTorch","count":3,"path":"api/tags/PyTorch.json"}],"author":{"name":"犬夜叉","slug":"blog-author","avatar":"https://i.imgur.com/CrgPA5H_d.png?maxwidth=520&shape=thumb&fidelity=high","link":"/","description":"一位喜欢犬夜叉的多模态大模型研究生","socials":{"github":"https://github.com/ziyi-wang2003","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/qq_62954485?spm=1000.2115.3001.5343","juejin":"","customs":{}}}}}