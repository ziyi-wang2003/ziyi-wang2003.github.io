{"title":"ViT 论文精读","uid":"290cb712ccbf87b18cb10d019f08a741","slug":"ViT精读","date":"2025-07-02T03:32:00.000Z","updated":"2025-07-02T07:54:06.046Z","comments":true,"path":"api/articles/ViT精读.json","keywords":null,"cover":"file-20250702125158402.png","content":"<p>参考笔记：<a href=\"https://juejin.cn/post/7153427278054031391\">ViT讲解</a></p>\n<p>Vision Transformer的出现标志着 Transformer 架构成功应用于计算机视觉领域，挑战了卷积神经网络在该领域的主导地位。ViT 通过将图像分割成小块 (patches)，并将这些图像块视为序列输入到标准的 Transformer 编码器中，从而实现了对图像的有效处理。这一进展不仅在图像分类等任务上取得了最先进的成果，更重要的是，它为视觉和语言（以及其他模态）提供了一种通用的架构语言——Transformer。这种架构上的统一极大地促进了后续多模态模型（如CLIP、LLaVA等，它们通常采用ViT或其变体作为视觉编码器）的设计和发展，使得不同模态的基于token的表示可以在相似的计算框架内进行交互和融合。 </p>\n<img src=\"/post/ViT%E7%B2%BE%E8%AF%BB/1.jpg\" class=\"\" title=\"ViT\">\n\n<p>从数据图中可以看出，在较小的数据集上，Vision Transformer比计算成本相当的ResNets更容易过拟合。例如，ViT-B/32比ResNet50稍快；它在9M子集上的表现要差得多，但在90M+子集上表现更好。ResNet152x2和ViT-L/16也是如此。这个结果强化了这样一种直觉：卷积的归纳偏置对于较小的数据集是有用的，但对于更大的数据集，直接从数据中学习相关模式是足够的，甚至是有益的。</p>\n<h2 id=\"I-摘要\"><a href=\"#I-摘要\" class=\"headerlink\" title=\"I. 摘要\"></a>I. 摘要</h2><p>尽管 Transformer 架构已成为自然语言处理（NLP）任务事实上的标准，但其在计算机视觉领域的应用仍然有限。在视觉领域，注意力机制要么与卷积网络（CNN）结合使用，要么用于替代卷积网络中的某些组件，但整体结构仍然保留。我们证明了这种对 CNN 的依赖并非必要，一个直接应用于图像块序列的纯 Transformer 模型可以在图像分类任务上表现得非常好。 当在大量数据上进行预训练，并迁移到多个中等或小型图像识别基准测试（如 ImageNet, CIFAR-100, VTAB 等）时，Vision Transformer (ViT) 相比于最先进的卷积网络取得了优异的结果，同时训练所需的计算资源也大幅减少。</p>\n<h2 id=\"II-创新点\"><a href=\"#II-创新点\" class=\"headerlink\" title=\"II. 创新点\"></a>II. 创新点</h2><h3 id=\"范式革新：将图像视为序列处理\"><a href=\"#范式革新：将图像视为序列处理\" class=\"headerlink\" title=\"范式革新：将图像视为序列处理\"></a>范式革新：将图像视为序列处理</h3><p>论文首次证明了一个纯粹的、标准的 Transformer 模型可以直接用于图像分类，而无需依赖卷积神经网络。传统视觉任务长期由 CNN 主导，这篇论文打破了这一惯例。它通过将图像分割成固定大小的图块，并将这些图块的线性嵌入序列作为 Transformer 的输入，成功地将 NLP 领域的成功范式迁移到了视觉领域。</p>\n<h3 id=\"数据量胜于归纳偏置\"><a href=\"#数据量胜于归纳偏置\" class=\"headerlink\" title=\"数据量胜于归纳偏置\"></a>数据量胜于归纳偏置</h3><p>论文发现，当在超大规模数据集（如 JFT-300M，包含3亿张图片）上进行预训练时，Vision Transformer (ViT) 的性能超越了当前最先进的卷积网络。这揭示了一个重要现象：CNN 中固有的（如局部性、平移不变性）的归纳偏置在数据量较小时非常有效，但当数据量足够大时，模型可以从数据中直接学习到这些空间关系，强大的模型容量和更少的先验限制反而成为优势。</p>\n<h3 id=\"卓越的计算效率和可扩展性\"><a href=\"#卓越的计算效率和可扩展性\" class=\"headerlink\" title=\"卓越的计算效率和可扩展性\"></a>卓越的计算效率和可扩展性</h3><p>与性能相当的 SOTA 卷积网络相比，ViT 在达到同等甚至更高精度时，所需的预训练计算资源要少得多。例如，ViT-L/16 在 JFT-300M 数据集上预训练后，其性能优于在同一数据集上训练的 BiT-L (一个大型 ResNet 模型)，而训练成本却显著降低。这证明了 Transformer 架构在可扩展性上的巨大潜力。</p>\n<h3 id=\"简洁而有效的模型设计\"><a href=\"#简洁而有效的模型设计\" class=\"headerlink\" title=\"简洁而有效的模型设计\"></a>简洁而有效的模型设计</h3><p>论文的设计理念是尽可能少地修改原始的 Transformer 架构，使其可以直接利用 NLP 领域成熟的高效实现和可扩展架构。这种简洁性不仅体现在模型结构上，也体现在对图像的处理上，除了初始的图块划分和用于适应不同分辨率的位置编码插值外，几乎没有引入图像特有的归纳偏置。</p>\n<h2 id=\"III-网络原理详解\"><a href=\"#III-网络原理详解\" class=\"headerlink\" title=\"III. 网络原理详解\"></a>III. 网络原理详解</h2><h3 id=\"ViT模型概览\"><a href=\"#ViT模型概览\" class=\"headerlink\" title=\"ViT模型概览\"></a>ViT模型概览</h3><p>ViT模型的核心思想是将图像转换为一个序列，然后用标准的Transformer Encoder来处理这个序列。</p>\n<h3 id=\"图像分块处理-Image-Patching\"><a href=\"#图像分块处理-Image-Patching\" class=\"headerlink\" title=\"图像分块处理 (Image Patching)\"></a>图像分块处理 (Image Patching)</h3><p>Transformer接受的输入数据格式是一维的词嵌入序列，为了处理二维图像数据，论文将图像 <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.09ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"12.767ex\" height=\"2.04ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -861.5 5643.2 901.5\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(849.8,0)\"><path data-c=\"2208\" d=\"M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(1794.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(792,363) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D43B\" d=\"M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(888,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1666,0)\"><path data-c=\"1D44A\" d=\"M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2714,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3492,0)\"><path data-c=\"1D436\" d=\"M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z\"></path></g></g></g></g></g></svg></mjx-container> 重塑为一个扁平化的二维图块序列 <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.65ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"14.517ex\" height=\"2.805ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -952.7 6416.3 1239.9\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1288.5,0)\"><path data-c=\"2208\" d=\"M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(2233.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(792,363) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D441\" d=\"M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(888,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1666,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(2055,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D443\" d=\"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(839.5,363) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(3298,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3576,0)\"><path data-c=\"1D436\" d=\"M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4336,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></g></g></svg></mjx-container>，其中：</p>\n<ul>\n<li><code>(H, W)</code> 是原始图像的分辨率</li>\n<li><code>C</code> 是通道数</li>\n<li><code>(P, P)</code> 是每个图像图块的分辨率</li>\n<li><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"13.35ex\" height=\"2.452ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -833.9 5900.6 1083.9\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D441\" d=\"M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1165.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2221.6,0)\"><path data-c=\"1D43B\" d=\"M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3109.6,0)\"><path data-c=\"1D44A\" d=\"M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(4157.6,0)\"><g data-mml-node=\"mo\"><path data-c=\"2F\" d=\"M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z\"></path></g></g><g data-mml-node=\"msup\" transform=\"translate(4657.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D443\" d=\"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(839.5,363) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></g></svg></mjx-container> 是最终得到的图块数量，<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.009ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 888 683\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D441\" d=\"M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z\"></path></g></g></g></svg></mjx-container> 也作为 Transformer 的有效输入序列长度。</li>\n</ul>\n<img src=\"/post/ViT%E7%B2%BE%E8%AF%BB/2.png\" class=\"\">\n<p>Transformer 在其所有层中使用恒定的潜在向量大小 <code>D</code>，因此论文将图块扁平化，并通过一个可训练的线性投影映射到 <code>D</code> 维。这个投影的输出称为图块嵌入 (Patch Embeddings)。<br>具体的分块实现可以使用卷积来实现，例如对于 <code>224x224x3</code> 的图像，可使用卷积核大小为 <code>16x16</code>、步长为 <code>16</code>，卷积核数量为 <code>768</code>，将原图像输出为 <code>14x14x768</code>，再将前两个维度展平，得到了最终的 <code>196x768</code> 的张量。</p>\n<img src=\"/post/ViT%E7%B2%BE%E8%AF%BB/3.png\" class=\"\">\n<h3 id=\"可学习的分类嵌入-Class-Token\"><a href=\"#可学习的分类嵌入-Class-Token\" class=\"headerlink\" title=\"可学习的分类嵌入 (Class Token)\"></a>可学习的分类嵌入 (Class Token)</h3><p>原论文在嵌入图块序列的前面添加一个类似于BERT的可学习的嵌入 <code>[CLS]</code> Token，用于对图像进行分类。<br>在进行物体分类任务时，如果不添加Class token，直接把 <code>196 x 768</code> 维的张量输入到编码器（Encode）中，编码器输出的同样是 <code>196 x 768</code> 维的张量，也就是196个 <code>1 x 768</code> 维的向量。但此时面临一个难题：难以确定该选取哪个向量作为最终的输出向量来进行物体分类。<br>为了解决上述问题，在将数据输入编码器之前，添加一个 <code>1 x 768</code> 维的向量，也就是Class token。这个向量会被放置在 <code>196 x 768</code> 维向量的前面。这样一来，编码器输出的向量维度就变成了 <code>197 x 768</code>。之后，只需通过切片操作获取第一个 <code>1 x 768</code> 维的向量，再把它送入分类头进行分类即可。</p>\n<h3 id=\"融合位置编码-Positional-Encoding\"><a href=\"#融合位置编码-Positional-Encoding\" class=\"headerlink\" title=\"融合位置编码 (Positional Encoding)\"></a>融合位置编码 (Positional Encoding)</h3><p>若不添加类似Transformer中的位置编码，那么ViT对于不同顺序的图块会得到相同的结果，这是违反直觉的。Transformer中使用的是正弦位置编码，ViT原始论文中使用的是一维可学习的位置嵌入，因为论文通过实验没有观察到使用二维感知位置嵌入会带来显著的性能提升。<br>在得到经过操作后的 <code>197 x 768</code> 维的张量（由 <code>1 x 768</code> 维的Class token和 <code>196 x 768</code> 维的张量x拼接而成）后，会加上一个维度同样为 <code>197 x 768</code> 的位置编码向量 <code>position Embedding</code>。由于二者维度相同，所以可以直接进行逐元素相加操作，这样就将位置信息融入到了嵌入向量中。<br>最终的输入数据为：<br><mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.869ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"71.953ex\" height=\"3.138ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -1002.7 31803.1 1386.9\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D467\" d=\"M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(498,-150) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mn\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(1179.3,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2235.1,0)\"><path data-c=\"5B\" d=\"M118 -250V750H255V710H158V-210H255V-250H118Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(2513.1,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(605,-150) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(433,0)\"><path data-c=\"1D459\" d=\"M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(731,0)\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1260,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1729,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(4722.3,0)\"><path data-c=\"3B\" d=\"M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z\"></path></g><g data-mml-node=\"msubsup\" transform=\"translate(5167,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(605,413) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mn\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(605,-247) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g></g></g><g data-mml-node=\"mi\" transform=\"translate(6177.7,0)\"><path data-c=\"1D438\" d=\"M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(6941.7,0)\"><path data-c=\"3B\" d=\"M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z\"></path></g><g data-mml-node=\"msubsup\" transform=\"translate(7386.3,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(605,413) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mn\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(605,-247) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g></g></g><g data-mml-node=\"mi\" transform=\"translate(8397,0)\"><path data-c=\"1D438\" d=\"M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(9161,0)\"><path data-c=\"3B\" d=\"M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(9605.7,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(10105.9,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(10606.1,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(10884.1,0)\"><path data-c=\"3B\" d=\"M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z\"></path></g><g data-mml-node=\"msubsup\" transform=\"translate(11328.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(605,413) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D441\" d=\"M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z\"></path></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(605,-247) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g></g></g><g data-mml-node=\"mi\" transform=\"translate(12611.7,0)\"><path data-c=\"1D438\" d=\"M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(13375.7,0)\"><path data-c=\"5D\" d=\"M22 710V750H159V-250H22V-210H119V710H22Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(13875.9,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(14876.1,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D438\" d=\"M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(771,-150) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(503,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(988,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(16727.4,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mstyle\" transform=\"translate(17005.4,0)\"><g data-mml-node=\"mspace\"></g></g><g data-mml-node=\"mi\" transform=\"translate(18172.1,0)\"><path data-c=\"1D438\" d=\"M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(19213.8,0)\"><path data-c=\"2208\" d=\"M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(20158.6,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"211D\" d=\"M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z\"></path></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(755,413) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(389,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D443\" d=\"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(839.5,363) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mn\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(1632,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1910,0)\"><path data-c=\"1D436\" d=\"M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2670,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3059,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3837,0)\"><path data-c=\"1D437\" d=\"M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(24262.3,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(24706.9,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D438\" d=\"M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(771,-150) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(503,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(988,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(26836,0)\"><path data-c=\"2208\" d=\"M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(27780.8,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"211D\" d=\"M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z\"></path></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(755,413) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(389,0)\"><path data-c=\"1D441\" d=\"M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1277,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(2055,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2555,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2944,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3722,0)\"><path data-c=\"1D437\" d=\"M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z\"></path></g></g></g></g></g></svg></mjx-container></p>\n<h3 id=\"Transformer-Encoder\"><a href=\"#Transformer-Encoder\" class=\"headerlink\" title=\"Transformer Encoder\"></a>Transformer Encoder</h3><p>ViT的 Encoder 使用的就是 Transformer Encoder 的结构，经过L个encoder结构后，输入维度没有发生变换，仍为 <code>197*768</code> 维。<br>Transformer 的 Encoder 接收输入序列后，先通过词嵌入和位置编码融合语义与位置信息，随后经过多层处理。每层先通过多头自注意力机制计算词与词之间的关联权重，动态聚合上下文信息，再经残差连接和层归一化稳定训练；接着通过前馈神经网络非线性变换特征，同样伴随残差与归一化。最终输出富含上下文信息的序列表示，核心在于自注意力的全局交互和层堆叠的渐进特征抽象。</p>\n<h3 id=\"MLP-Head-分类头\"><a href=\"#MLP-Head-分类头\" class=\"headerlink\" title=\"MLP Head (分类头)\"></a>MLP Head (分类头)</h3><p>经过encoder结构后，输出的维度为 <code>197*768</code>，此时我们会通过切片的方式提取出Class token的信息，其维度为 <code>1*768</code>。接着会拿这个 <code>1*768</code> 维的Class token经过MLP Head层。<br>ViT中的MLP Head结构非常简洁，它的设计目标是作为一个简单的线性分类器，将从 <code>[CLS]</code> Token中提取到的高度浓缩的图像特征映射到最终的分类结果上。在最常见的实现中，MLP Head仅仅由一个线性层构成。输入维度等于Transformer模型内部的隐藏维度，输出维度等于任务所需的类别总数。<br>在某些论文或实现中（特别是在预训练阶段），这个MLP Head可能会稍微复杂一点，比如包含一个 <code>tanh</code> 激活函数和一个线性层，即 <code>Linear(tanh(Input))</code>。但在将预训练好的模型应用于下游任务时，通常会丢弃预训练的MLP Head，换上一个全新的、符合新任务类别数量的单线性层。<br>ViT整体结构如下图所示：<br><img src=\"/post/ViT%E7%B2%BE%E8%AF%BB/file-20250702124705978.png\"><br><img src=\"/post/ViT%E7%B2%BE%E8%AF%BB/7034907f-3ba0-45a9-b3f9-b859357c30ef.gif\"></p>\n<h2 id=\"IV-ViT代码复现\"><a href=\"#IV-ViT代码复现\" class=\"headerlink\" title=\"IV. ViT代码复现\"></a>IV. ViT代码复现</h2><h3 id=\"1-Patch-Embedding\"><a href=\"#1-Patch-Embedding\" class=\"headerlink\" title=\"1. Patch Embedding\"></a>1. Patch Embedding</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> functools <span class=\"keyword\">import</span> partial</span><br><span class=\"line\"><span class=\"keyword\">from</span> collections <span class=\"keyword\">import</span> OrderedDict</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">PatchEmbed</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    将图像分割成块 (patch) 并进行线性嵌入</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, img_size=<span class=\"number\">224</span>, patch_size=<span class=\"number\">16</span>, in_c=<span class=\"number\">3</span>, embed_dim=<span class=\"number\">768</span>, norm_layer=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">        <span class=\"comment\"># img_size 输入图片大小 | patch_size 图片分块大小 | in_c 输入通道数 | embed_dim 嵌入后的维度</span></span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        img_size = (img_size, img_size)</span><br><span class=\"line\">        patch_size = (patch_size, patch_size)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.img_size = img_size</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.patch_size = patch_size</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.grid_size = (img_size[<span class=\"number\">0</span>] // patch_size[<span class=\"number\">0</span>], img_size[<span class=\"number\">1</span>] // patch_size[<span class=\"number\">1</span>])</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.num_patches = <span class=\"variable language_\">self</span>.grid_size[<span class=\"number\">0</span>] * <span class=\"variable language_\">self</span>.grid_size[<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 使用二维卷积实现分块和嵌入 (B,3,224,224) -&gt; (B,768,14,14)</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.proj = nn.Conv2d(in_c, embed_dim, kernel_size=patch_size, stride=patch_size)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.norm = norm_layer(embed_dim) <span class=\"keyword\">if</span> norm_layer <span class=\"keyword\">else</span> nn.Identity()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        B, C, H, W = x.shape</span><br><span class=\"line\">        <span class=\"keyword\">assert</span> H == <span class=\"variable language_\">self</span>.img_size[<span class=\"number\">0</span>] <span class=\"keyword\">and</span> W == <span class=\"variable language_\">self</span>.img_size[<span class=\"number\">1</span>], \\</span><br><span class=\"line\">            <span class=\"string\">f\"输入图像大小<span class=\"subst\">{H}</span>*<span class=\"subst\">{W}</span>与模型期望大小<span class=\"subst\">{self.img_size[<span class=\"number\">0</span>]}</span>*<span class=\"subst\">{self.img_size[<span class=\"number\">1</span>]}</span>不匹配\"</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># (B,768,14,14) --flatten--&gt; (B,768,196) --transpose--&gt; (B,196,768)</span></span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.proj(x).flatten(<span class=\"number\">2</span>).transpose(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.norm(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> x</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-multi-head\"><a href=\"#2-multi-head\" class=\"headerlink\" title=\"2. multi-head\"></a>2. multi-head</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Attention</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self,</span></span><br><span class=\"line\"><span class=\"params\">                 dim,  <span class=\"comment\"># 输入的token维度,768</span></span></span><br><span class=\"line\"><span class=\"params\">                 num_heads = <span class=\"number\">8</span>, <span class=\"comment\"># 注意力头数,为8</span></span></span><br><span class=\"line\"><span class=\"params\">                 qkv_bias=<span class=\"literal\">False</span>, <span class=\"comment\"># 生成QKV的时候是否添加偏置</span></span></span><br><span class=\"line\"><span class=\"params\">                 qk_scale=<span class=\"literal\">None</span>, <span class=\"comment\"># 用于缩放QK的系数,如果None,则使用1/sqrt(head_dim)</span></span></span><br><span class=\"line\"><span class=\"params\">                 atte_drop_ration=<span class=\"number\">0.</span>, <span class=\"comment\"># 注意力分数的dropout比率</span></span></span><br><span class=\"line\"><span class=\"params\">                 proj_drop_ration=<span class=\"number\">0.</span></span>): <span class=\"comment\"># 最终投影层的dropout比率</span></span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.num_heads = num_heads <span class=\"comment\"># 注意力头数</span></span><br><span class=\"line\">        head_dim = dim // num_heads  <span class=\"comment\"># 每个注意力头数的维度</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.scale = qk_scale <span class=\"keyword\">or</span> head_dim ** -<span class=\"number\">0.5</span>  <span class=\"comment\">#qk的缩放因子</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.qkv = nn.Linear(dim,dim*<span class=\"number\">3</span>,bisa=qkv_bias) <span class=\"comment\"># 通过全连接层生成QKV,为了并行计算,提高计算效率,参数更少</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">        这是实现多头注意力的一个巧妙且高效的方式。</span></span><br><span class=\"line\"><span class=\"string\">        它用一个全连接层，一次性地将输入 x (维度为 dim) 映射到一个维度为 dim * 3 的张量。</span></span><br><span class=\"line\"><span class=\"string\">        这个 dim * 3 的张量可以被看作是 Q, K, V 三个部分横向拼接在一起的结果，</span></span><br><span class=\"line\"><span class=\"string\">        后续我们只需要对这个大张量进行切分即可。</span></span><br><span class=\"line\"><span class=\"string\">        这样做比定义三个独立的线性层(一个给Q,一个给K,一个给V)在计算上更高效。</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.atte_drop = nn.Dropout(atte_drop_ration)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.proj_drop = nn.Dropout(proj_drop_ration)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.proj = nn.Linear(dim,dim) <span class=\"comment\"># 将每个head得到的输出进行concat拼接,然后通过线性变换映射为原本的嵌入dim</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self,x</span>):</span><br><span class=\"line\">        B,N,C = x.shape  <span class=\"comment\"># 批大小, 图块数+1(这个1为class_token), 通道数</span></span><br><span class=\"line\">        <span class=\"comment\"># reshape: B,N,3*C -&gt; B,N,3,num_head,C//num_head</span></span><br><span class=\"line\">        <span class=\"comment\"># permute: B,N,3,num_head,C//num_head  -&gt;  3,B,num_heads,N,C//self.num_heads</span></span><br><span class=\"line\">        <span class=\"comment\">#这样一来，Q, K, V就被分开了，并且每个头的计算所需的数据（N 和 head_dim）都排列在一起，非常适合进行批处理矩阵运算</span></span><br><span class=\"line\">        qkv = <span class=\"variable language_\">self</span>.qkv(x).reshape(B,N,<span class=\"number\">3</span>,<span class=\"variable language_\">self</span>.num_head,C//<span class=\"variable language_\">self</span>.num_head).permute(<span class=\"number\">2</span>,<span class=\"number\">0</span>,<span class=\"number\">3</span>,<span class=\"number\">1</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 用切片拿到q,k,v. 形状都是: [B, num_heads, N, head_dim]</span></span><br><span class=\"line\">        q,k,v = qkv[<span class=\"number\">0</span>],qkv[<span class=\"number\">1</span>],qkv[<span class=\"number\">2</span>]</span><br><span class=\"line\">        <span class=\"comment\"># transpose: (B,num_heads,N,C//self.num_heads)  -&gt;  (B,num_heads,C//self.num_heads,N)</span></span><br><span class=\"line\">        <span class=\"comment\"># 这是一个批处理矩阵乘法。对于 B 个样本中的每一个和 num_heads 个头中的每一个，</span></span><br><span class=\"line\">        <span class=\"comment\"># 我们都计算一个 [N, head_dim] 的 q 矩阵和一个 [head_dim, N] 的 k 转置矩阵的乘积</span></span><br><span class=\"line\">        <span class=\"comment\"># 结果是一个 [N, N] 的矩阵，这个矩阵的第 (i, j) 个元素表示序列中第 i 个 token 对第 j 个 token 的注意力分数</span></span><br><span class=\"line\">        attn = (q @ k.transpose(-<span class=\"number\">2</span>,-<span class=\"number\">1</span>))*<span class=\"variable language_\">self</span>.scale  <span class=\"comment\">#形状为[B,num_heads,N,N] </span></span><br><span class=\"line\">        attn = attn.softmax(dim=-<span class=\"number\">1</span>) <span class=\"comment\"># 对每个头的注意力分数矩阵的 每一行 进行归一化，使其和为1</span></span><br><span class=\"line\">        attn = <span class=\"variable language_\">self</span>.atte_drop(attn) <span class=\"comment\"># 应用dropout</span></span><br><span class=\"line\">        <span class=\"comment\"># 注意力权重对V进行加权求和</span></span><br><span class=\"line\">        <span class=\"comment\"># attn @ V: B,num_heads,N,C//self.num_heads</span></span><br><span class=\"line\">        <span class=\"comment\"># transpose(1,2): B,N,num_heads,C//self.num_heads</span></span><br><span class=\"line\">        <span class=\"comment\"># reshape(B,N,C): 将最后两个维度信息拼接,合并多个头输出,回到总的嵌入维度</span></span><br><span class=\"line\">        x = (attn @ v).transpose(<span class=\"number\">1</span>,<span class=\"number\">2</span>).reshape(B,N,C)</span><br><span class=\"line\">        <span class=\"comment\"># 将拼接好的多头输出通过最后一个线性层 self.proj。这一步允许模型学习如何最好地融合来自不同头的信息</span></span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.proj(x)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.proj_drop(x) <span class=\"comment\"># 应用最后的 dropout，防止过拟合</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> x</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"3-Block\"><a href=\"#3-Block\" class=\"headerlink\" title=\"3. Block\"></a>3. Block</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MLP</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self,in_features,hidden_features=<span class=\"literal\">None</span>,out_features=<span class=\"literal\">None</span>,act_layer=nn.GELU,drop=<span class=\"number\">0.</span></span>):</span><br><span class=\"line\">        <span class=\"comment\"># in_features输入的维度  hidden_features隐藏层的维度,通常为in_features的4倍  out_features输出的维度,通常与in_features相同</span></span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        out_features = out_features <span class=\"keyword\">or</span> in_features</span><br><span class=\"line\">        hidden_features = hidden_features <span class=\"keyword\">or</span> in_features</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.fc1 = nn.Linear(in_features,hidden_features)   <span class=\"comment\"># 第一个全连接层</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.act = act_layer()  <span class=\"comment\"># 激活层,默认GELU函数</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.fc2 = nn.Linear(hidden_features,out_features)  <span class=\"comment\"># 第二个全连接层</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.drop = nn.Dropout(drop)   <span class=\"comment\"># dropout层</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self,x</span>):</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.fc1(x)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.act(x)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.drop(x)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.fc2(x)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.drop(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> x</span><br><span class=\"line\">        </span><br><span class=\"line\">        </span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">drop_path</span>(<span class=\"params\">x, drop_prob:<span class=\"built_in\">float</span> = <span class=\"number\">0.</span>, training: <span class=\"built_in\">bool</span> = <span class=\"literal\">False</span></span>):</span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    实现DropPath的核心功能。</span></span><br><span class=\"line\"><span class=\"string\">    以 drop_prob 的概率将输入的整个张量 x 置零。</span></span><br><span class=\"line\"><span class=\"string\">    这是 Stochastic Depth 网络中的主要正则化方法。</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    <span class=\"comment\"># 如果丢弃概率为0，或者当前不是训练模式，则直接返回原始输入x</span></span><br><span class=\"line\">    <span class=\"comment\"># 在评估或推理时，我们不希望随机丢弃任何路径</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> drop_prob == <span class=\"number\">0.</span> <span class=\"keyword\">or</span> <span class=\"keyword\">not</span> training:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> x</span><br><span class=\"line\">    keep_prob = <span class=\"number\">1</span>-drop_prob   <span class=\"comment\"># 计算需要保留的路径的概率 (keep_prob)</span></span><br><span class=\"line\">    <span class=\"comment\"># 创建一个生成随即掩码的形状元组，shape会是 (batch_size, 1, 1, ...)，1的数量取决于x的维度</span></span><br><span class=\"line\">    shape = (x.shape[<span class=\"number\">0</span>],) + (<span class=\"number\">1</span>,)*(x.ndim - <span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"comment\"># 生成一个随机张量。torch.rand生成[0, 1)之间的均匀分布随机数。</span></span><br><span class=\"line\">    <span class=\"comment\"># 加上keep_prob后，random_tensor的范围变为 [keep_prob, 1 + keep_prob)</span></span><br><span class=\"line\">    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.devide)</span><br><span class=\"line\">    <span class=\"comment\"># floor_(): 对随机张量进行向下取整</span></span><br><span class=\"line\">    <span class=\"comment\"># 结果是：原先在 [keep_prob, 1) 区间的数值变为0，原先在 [1, 1 + keep_prob) 区间的数值变为1</span></span><br><span class=\"line\">    <span class=\"comment\"># 一个数落在 [1, 1+keep_prob) 的概率恰好是 keep_prob</span></span><br><span class=\"line\">    <span class=\"comment\"># 这样，random_tensor就变成了一个二值掩码（0或1）</span></span><br><span class=\"line\">    random_tensor.floor_()</span><br><span class=\"line\">    <span class=\"comment\"># 将输入x除以keep_prob，然后乘以二值掩码</span></span><br><span class=\"line\">    <span class=\"comment\"># 乘以random_tensor：将一部分样本的整个张量置零（实现DropPath）。</span></span><br><span class=\"line\">    <span class=\"comment\"># 除以keep_prob：这是一种被称为\"Inverted Dropout\"的技术。通过在训练时放大保留下来的输出，</span></span><br><span class=\"line\">    <span class=\"comment\"># 可以保证在推理时（此时keep_prob为1，不做任何操作）网络的期望输出与训练时保持一致，无需在推理阶段进行额外的缩放</span></span><br><span class=\"line\">    output = x.div(keep_prob)*random_tensor</span><br><span class=\"line\">    <span class=\"keyword\">return</span> output</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">DropPath</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, drop_prob=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(DropPath,<span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.drop_prob = drop_prob</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self,x</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> drop_path(x,<span class=\"variable language_\">self</span>.drop_prob,<span class=\"variable language_\">self</span>.training) </span><br><span class=\"line\">        </span><br><span class=\"line\">        </span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Block</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self,</span></span><br><span class=\"line\"><span class=\"params\">                 dim, <span class=\"comment\"># 每个token的维度</span></span></span><br><span class=\"line\"><span class=\"params\">                 num_heads,  <span class=\"comment\">#多头自注意力的头数量</span></span></span><br><span class=\"line\"><span class=\"params\">                 mlp_ratio=<span class=\"number\">4</span>,  <span class=\"comment\">#计算hidden_features大小 为输入的四倍</span></span></span><br><span class=\"line\"><span class=\"params\">                 qkv_bias=<span class=\"literal\">False</span>,  <span class=\"comment\"># qkv偏置</span></span></span><br><span class=\"line\"><span class=\"params\">                 qk_scale = <span class=\"literal\">None</span>,  <span class=\"comment\"># 注意力缩放因子</span></span></span><br><span class=\"line\"><span class=\"params\">                 drop_ratio=<span class=\"number\">0.</span>,  <span class=\"comment\"># 多头自注意力机制的最后dropout比例</span></span></span><br><span class=\"line\"><span class=\"params\">                 attn_drop_ratio=<span class=\"number\">0.</span>,  <span class=\"comment\"># 生成qkv之后的dropout比例</span></span></span><br><span class=\"line\"><span class=\"params\">                 drop_path_ratio=<span class=\"number\">0.</span>, <span class=\"comment\"># drop_path比例</span></span></span><br><span class=\"line\"><span class=\"params\">                 act_layer=nn.GELU,  <span class=\"comment\"># 激活函数</span></span></span><br><span class=\"line\"><span class=\"params\">                 norm_layer=nn.LayerNorm  <span class=\"comment\"># 正则化层</span></span></span><br><span class=\"line\"><span class=\"params\">                 </span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Block,<span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.norm1 = norm_layer(dim) <span class=\"comment\"># transformer encoder 中的第一个norm层</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.attn = Attention(dim,num_heads=num_heads,qkv_bias=qkv_bias,qk_scale=qk_scale,</span><br><span class=\"line\">                              attn_drop_ratio=attn_drop_ratio,proj_drop_ration=drop_ratio)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.drop_path = DropPath(drop_path_ratio) <span class=\"keyword\">if</span> drop_path_ratio <span class=\"keyword\">else</span> nn.Identity()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.norm2 = norm_layer(dim)  <span class=\"comment\"># 定义第二个layer_norm层</span></span><br><span class=\"line\">        mlp_hidden_dim = <span class=\"built_in\">int</span>(dim*mlp_ratio)</span><br><span class=\"line\">        <span class=\"comment\"># 定义mlp层</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.mlp = MLP(in_features=dim,hidden_features=mlp_hidden_dim,act_layer=act_layer,drop=drop_ratio)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self,x</span>):</span><br><span class=\"line\">        x = x + <span class=\"variable language_\">self</span>.drop_path(<span class=\"variable language_\">self</span>.attn(<span class=\"variable language_\">self</span>.norm1(x))) <span class=\"comment\"># 前向传播部分，输入的x先经过layernorm再经过多头注意力</span></span><br><span class=\"line\">        x = x + <span class=\"variable language_\">self</span>.drop_path(<span class=\"variable language_\">self</span>.mlp(<span class=\"variable language_\">self</span>.norm2(x)))  <span class=\"comment\"># 将得到的x一次通过layernorm、mlp、drop_path        </span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"4-Vision-Transformer\"><a href=\"#4-Vision-Transformer\" class=\"headerlink\" title=\"4. Vision Transformer\"></a>4. Vision Transformer</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">_init_vit_weights</span>(<span class=\"params\">m</span>):</span><br><span class=\"line\">    <span class=\"comment\"># 1. 如果是全连接层</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(m,nn.Linear):</span><br><span class=\"line\">        <span class=\"comment\"># 使用截断正态分布进行初始化，这是原始ViT论文推荐的方法</span></span><br><span class=\"line\">        <span class=\"comment\"># 截断正态分布可以防止权重值离均值太远，让初始状态更稳定</span></span><br><span class=\"line\">        <span class=\"comment\"># std=0.02 是一个经验值。带下划线的方法表示这是个in-place（原地）操作</span></span><br><span class=\"line\">        nn.init.trunc_normal_(m.weight,std=<span class=\"number\">0.01</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 如果该线性层有偏置(bias)项</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> m.bias <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 将偏置初始化为0</span></span><br><span class=\"line\">            nn.init.zeros_(m.bias)</span><br><span class=\"line\">    <span class=\"comment\"># 2. 如果是2D卷积层</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> <span class=\"built_in\">isinstance</span>(m,nn.Conv2d):</span><br><span class=\"line\">        <span class=\"comment\"># 使用Kaiming正态分布初始化。这是一种非常适合带有ReLU激活函数的卷积层的初始化方法</span></span><br><span class=\"line\">        <span class=\"comment\"># 它可以有效防止梯度消失或爆炸</span></span><br><span class=\"line\">        <span class=\"comment\"># mode=\"fan_out\" 表示根据输出通道数来调整方差</span></span><br><span class=\"line\">        nn.init.kaiming_normal_(m.weight,mode=<span class=\"string\">\"fan_out\"</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 如果该卷积层有偏置项</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> m.bias <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 将偏置项初始化为0</span></span><br><span class=\"line\">            nn.init.zeros_(m.bias)</span><br><span class=\"line\">    <span class=\"comment\"># 3. 如果是层归一化层</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> <span class=\"built_in\">isinstance</span>(m,nn.LayerNorm):</span><br><span class=\"line\">        <span class=\"comment\"># 将偏置初始化为0</span></span><br><span class=\"line\">        nn.init.zeros_(m.bias)</span><br><span class=\"line\">        <span class=\"comment\"># 将权重初始化为1</span></span><br><span class=\"line\">        nn.init.ones_(m.weight)</span><br><span class=\"line\">        <span class=\"comment\"># 这样做的目的是，当训练刚开始时，LayerNorm层几乎等同于一个恒等映射，不会改变输入的分布，让训练更稳定</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">VisionTransformer</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, img_size=<span class=\"number\">224</span>,patch_size=<span class=\"number\">16</span>,in_c=<span class=\"number\">3</span>,num_classes=<span class=\"number\">1000</span>,</span></span><br><span class=\"line\"><span class=\"params\">                 embed_dim=<span class=\"number\">768</span>,depth=<span class=\"number\">12</span>,num_head=<span class=\"number\">12</span>,mlp_ratio=<span class=\"number\">4.0</span>,qkv_bias=<span class=\"literal\">True</span>,</span></span><br><span class=\"line\"><span class=\"params\">                 qk_scale=<span class=\"literal\">None</span>,representation_size=<span class=\"literal\">None</span>,distilled=<span class=\"literal\">False</span>,drop_ratio=<span class=\"number\">0.</span>,</span></span><br><span class=\"line\"><span class=\"params\">                 attn_drop_ratio=<span class=\"number\">0.</span>,drop_path_ratio=<span class=\"number\">0.</span>,embed_layer=PatchEmbed,norm_layer=<span class=\"literal\">None</span>,</span></span><br><span class=\"line\"><span class=\"params\">                 act_layer=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">        <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">        ViT模型构造函数。</span></span><br><span class=\"line\"><span class=\"string\">        Args:</span></span><br><span class=\"line\"><span class=\"string\">            img_size (int): 输入图像的尺寸</span></span><br><span class=\"line\"><span class=\"string\">            patch_size (int): 每个图像块(patch)的尺寸</span></span><br><span class=\"line\"><span class=\"string\">            in_c (int): 输入图像的通道数</span></span><br><span class=\"line\"><span class=\"string\">            num_classes (int): 最终分类的类别数</span></span><br><span class=\"line\"><span class=\"string\">            embed_dim (int): Token的嵌入维度 (D)</span></span><br><span class=\"line\"><span class=\"string\">            depth (int): Transformer Encoder的总层数</span></span><br><span class=\"line\"><span class=\"string\">            num_head (int): 多头注意力机制中的头数</span></span><br><span class=\"line\"><span class=\"string\">            mlp_ratio (float): Transformer Encoder中MLP层的维度扩展比例</span></span><br><span class=\"line\"><span class=\"string\">            qkv_bias (bool): 是否在Q,K,V生成时使用偏置</span></span><br><span class=\"line\"><span class=\"string\">            qk_scale (float, optional): QK缩放因子，默认为 1/sqrt(head_dim)</span></span><br><span class=\"line\"><span class=\"string\">            representation_size (int, optional): 在最终分类头之前，可选的中间全连接层维度</span></span><br><span class=\"line\"><span class=\"string\">            distilled (bool): 是否使用蒸馏模式 (DeiT模型)</span></span><br><span class=\"line\"><span class=\"string\">            drop_ratio (float): 全局Dropout比率</span></span><br><span class=\"line\"><span class=\"string\">            attn_drop_ratio (float): 注意力权重Dropout比率</span></span><br><span class=\"line\"><span class=\"string\">            drop_path_ratio (float): 随机深度的DropPath比率</span></span><br><span class=\"line\"><span class=\"string\">            embed_layer (nn.Module): 用于生成Patch Embedding的层</span></span><br><span class=\"line\"><span class=\"string\">            norm_layer (nn.Module, optional): 使用的归一化层</span></span><br><span class=\"line\"><span class=\"string\">            act_layer (nn.Module, optional): 使用的激活函数层</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        <span class=\"comment\"># 调用父类nn.Module的初始化方法</span></span><br><span class=\"line\">        <span class=\"built_in\">super</span>(VisionTransformer,<span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.num_classes = num_classes <span class=\"comment\"># 保存分类数</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.num_features = <span class=\"variable language_\">self</span>.embed_dim = embed_dim <span class=\"comment\"># 保存嵌入维度</span></span><br><span class=\"line\">        <span class=\"comment\"># 判断是否使用蒸馏。如果使用，会多一个distillation token，总共2个特殊token；否则只有cls_token，1个</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.num_tokens = <span class=\"number\">2</span> <span class=\"keyword\">if</span> distilled <span class=\"keyword\">else</span> <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"comment\"># 如果未指定归一化层，则默认使用LayerNorm，并设置eps以增加数值稳定性。</span></span><br><span class=\"line\">        <span class=\"comment\"># partial用于创建一个预设了部分参数的新函数</span></span><br><span class=\"line\">        norm_layer = norm_layer <span class=\"keyword\">or</span> partial(nn.LayerNorm,eps=<span class=\"number\">1e-6</span>)</span><br><span class=\"line\">        <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">        partial 来自 Python 内置的 functools 模块，它的作用是将一个函数的某些参数“冻结”住，从而创建一个新的、更简单的函数</span></span><br><span class=\"line\"><span class=\"string\">        此处的意义是将所有nn.LayerNorm的eps固定为1e-6</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        act_layer = act_layer <span class=\"keyword\">or</span> nn.GELU() <span class=\"comment\"># 如果未指定激活函数，则默认使用GELU</span></span><br><span class=\"line\">        <span class=\"comment\"># 1. Patch Embedding层：将输入的图片(B, C, H, W)转换为一系列token(B, N, D)</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.patch_embed = embed_layer(img_size=img_size,patch_size=patch_size,in_c=in_c,embed_dim=embed_dim)</span><br><span class=\"line\">        <span class=\"comment\"># 获取patch的数量</span></span><br><span class=\"line\">        num_patches = <span class=\"variable language_\">self</span>.patch_embed.num_patches  </span><br><span class=\"line\">        <span class=\"comment\"># 2. 定义可学习的 [CLS] token。这个token最终的输出将代表整个图像的特征用于分类</span></span><br><span class=\"line\">        <span class=\"comment\"># 初始形状为(1, 1, embed_dim)，1个token，维度为embed_dim</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.cls_token = nn.Parameter(torch.zeros(<span class=\"number\">1</span>,<span class=\"number\">1</span>,embed_dim))</span><br><span class=\"line\">        <span class=\"comment\"># 3. 如果是蒸馏模式，定义可学习的 [DIST] token</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.dist_token = nn.Parameter(torch.zeros(<span class=\"number\">1</span>,<span class=\"number\">1</span>,embed_dim)) <span class=\"keyword\">if</span> distilled <span class=\"keyword\">else</span> <span class=\"literal\">None</span></span><br><span class=\"line\">        <span class=\"comment\"># 4. 定义可学习的位置编码(Positional Embedding)。因为Transformer本身不感知顺序，需要它来提供位置信息</span></span><br><span class=\"line\">        <span class=\"comment\"># 长度为 patch数量 + 特殊token数量</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.pos_embed = nn.Parameter(torch.zeros(<span class=\"number\">1</span>,num_patches+<span class=\"variable language_\">self</span>.num_tokens,embed_dim))</span><br><span class=\"line\">        <span class=\"comment\"># 5. 在位置编码加入后，应用一个Dropout层</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.pos_drop = nn.Dropout(p = drop_ratio)</span><br><span class=\"line\">        <span class=\"comment\"># 6. 构建随机深度(Stochastic Depth)的衰减率序列</span></span><br><span class=\"line\">        <span class=\"comment\"># torch.linspace生成一个从0到drop_path_ratio的等差序列，长度为depth</span></span><br><span class=\"line\">        <span class=\"comment\"># 这样，越深的Block，其drop_path_ratio越大，被\"丢弃\"的概率也越高</span></span><br><span class=\"line\">        dpr = [x.item() <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> torch.linspace(<span class=\"number\">0</span>,drop_path_ratio,depth)]</span><br><span class=\"line\">        <span class=\"comment\"># 7. 构建Transformer Encoder主体，由连续的Block堆叠而成</span></span><br><span class=\"line\">        <span class=\"comment\"># 使用nn.Sequential将多个Block串联起来</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.block = nn.Sequential(*[</span><br><span class=\"line\">            Block(dim=embed_dim,num_heads=num_head,mlp_ratio=mlp_ratio,qkv_bias=qkv_bias,qk_scale=qk_scale,</span><br><span class=\"line\">                  drop_ratio = drop_ratio,attn_drop_ratio=attn_drop_ratio,drop_path_ratio=dpr[i],</span><br><span class=\"line\">                  norm_layer=norm_layer,act_layer=act_layer)</span><br><span class=\"line\">            <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(depth)</span><br><span class=\"line\">        ])</span><br><span class=\"line\">        <span class=\"comment\"># 8. 经过所有Transformer Block后的最后一个LayerNorm层。</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.norm = norm_layer(embed_dim)</span><br><span class=\"line\">        <span class=\"comment\"># 9. 定义分类头之前的一个可选的\"pre-logits\"层 (常用于从JFT等大数据集预训练后迁移学习)</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> representation_size <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> distilled:</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.has_logits = <span class=\"literal\">True</span></span><br><span class=\"line\">            <span class=\"comment\"># 更新最终输出的特征维度</span></span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.num_features = representation_size</span><br><span class=\"line\">            <span class=\"comment\"># pre_logits是一个包含全连接层和Tanh激活的序列</span></span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.pre_logits = nn.Sequential(OrderedDict([</span><br><span class=\"line\">                (<span class=\"string\">\"fc\"</span>,nn.Linear(embed_dim,representation_size)),</span><br><span class=\"line\">                (<span class=\"string\">\"act\"</span>,nn.Tanh())</span><br><span class=\"line\">            ]))</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.has_logits=<span class=\"literal\">False</span></span><br><span class=\"line\">            <span class=\"comment\"># 如果不使用，则用一个恒等映射层代替</span></span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.pre_logits=nn.Identity()</span><br><span class=\"line\">        <span class=\"comment\"># 10. 定义最终的分类头 (Head)</span></span><br><span class=\"line\">        <span class=\"comment\"># 将提取的特征映射到最终的分类数</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.head = nn.Linear(<span class=\"variable language_\">self</span>.num_features,num_classes) <span class=\"keyword\">if</span> num_classes&gt;<span class=\"number\">0</span> <span class=\"keyword\">else</span> nn.Identity()</span><br><span class=\"line\">        <span class=\"comment\"># 11. 如果是蒸馏模式，为distillation token也定义一个分类头</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.head_dist = <span class=\"literal\">None</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> distilled:</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.head_dist = nn.Linear(<span class=\"variable language_\">self</span>.embed_dim,<span class=\"variable language_\">self</span>.num_classes) <span class=\"keyword\">if</span> num_classes&gt;<span class=\"number\">0</span> <span class=\"keyword\">else</span> nn.Identity()</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 12. 权重初始化</span></span><br><span class=\"line\">        <span class=\"comment\"># 对位置编码、dist_token、cls_token进行截断正态分布初始化</span></span><br><span class=\"line\">        nn.init.trunc_normal_(<span class=\"variable language_\">self</span>.pos_embed,std=<span class=\"number\">0.02</span>)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"variable language_\">self</span>.dist_token <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            nn.init.trunc_normal_(<span class=\"variable language_\">self</span>.dist_token,std=<span class=\"number\">0.02</span>)</span><br><span class=\"line\">        nn.init.trunc_normal_(<span class=\"variable language_\">self</span>.cls_token,std=<span class=\"number\">0.02</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 使用self.apply()方法，将_init_vit_weights函数递归地应用到模型的所有子模块上</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.apply(_init_vit_weights)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward_features</span>(<span class=\"params\">self,x</span>):</span><br><span class=\"line\">        <span class=\"string\">\"\"\"提取特征的前向传播过程，不包括最后的分类头。\"\"\"</span></span><br><span class=\"line\">        <span class=\"comment\"># x 初始形状: [B, C, H, W]</span></span><br><span class=\"line\">        <span class=\"comment\"># 1. Patch Embedding: [B, C, H, W] -&gt; [B, num_patches, embed_dim]</span></span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.patch_embed(x)</span><br><span class=\"line\">        <span class=\"comment\"># 2. 将cls_token在batch维度上进行扩展，以匹配输入x的batch_size</span></span><br><span class=\"line\">        <span class=\"comment\"># expand()是一个高效的操作，它不会实际复制数据</span></span><br><span class=\"line\">        cls_token = <span class=\"variable language_\">self</span>.cls_token.expand(x.shape[<span class=\"number\">0</span>],-<span class=\"number\">1</span>,-<span class=\"number\">1</span>) <span class=\"comment\"># [1, 1, D] -&gt; [B, 1, D]</span></span><br><span class=\"line\">        <span class=\"comment\"># 3. 将特殊token与patch token拼接在一起</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"variable language_\">self</span>.dist_token <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 若没有蒸馏token，拼接: [B, 1, D] 和 [B, N, D] -&gt; [B, N+1, D]</span></span><br><span class=\"line\">            x = torch.cat((cls_token,x),dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 蒸馏模式下，拼接cls_token和dist_token</span></span><br><span class=\"line\">            x = torch.cat((cls_token,<span class=\"variable language_\">self</span>.dist_token.expand(x.shape[<span class=\"number\">0</span>],-<span class=\"number\">1</span>,-<span class=\"number\">1</span>),x),dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 4. 加上位置编码，然后应用dropout</span></span><br><span class=\"line\">        <span class=\"comment\"># pos_embed的[B]维度会自动广播以匹配x</span></span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.pos_drop(x+<span class=\"variable language_\">self</span>.pos_embed)</span><br><span class=\"line\">        <span class=\"comment\"># 5. 通过Transformer Encoder主干网络</span></span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.block(x)</span><br><span class=\"line\">        <span class=\"comment\"># 6. 通过最后的LayerNorm</span></span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.norm(x)</span><br><span class=\"line\">        <span class=\"comment\"># 7. 提取用于分类的token的输出</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"variable language_\">self</span>.dist_token <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 只返回cls_token的输出 (在序列的第0个位置)，并通过pre_logits层</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.pre_logits(x[:,<span class=\"number\">0</span>])</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 返回cls_token和dist_token的输出</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> x[:,<span class=\"number\">0</span>],x[:,<span class=\"number\">1</span>]</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self,x</span>):</span><br><span class=\"line\">        <span class=\"string\">\"\"\"完整的从输入到输出的前向传播过程。\"\"\"</span></span><br><span class=\"line\">        <span class=\"comment\"># 1. 首先通过forward_features提取特征</span></span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.forward_features(x)</span><br><span class=\"line\">        <span class=\"comment\"># 2. 通过最后的分类头得到logits</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"variable language_\">self</span>.head_dist <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 蒸馏模式下，两个token分别通过各自的分类头</span></span><br><span class=\"line\">            <span class=\"comment\"># x此时是一个元组 (cls_output, dist_output)</span></span><br><span class=\"line\">            x_cls,x_dist = <span class=\"variable language_\">self</span>.head(x[<span class=\"number\">0</span>]),<span class=\"variable language_\">self</span>.head_dist(x[<span class=\"number\">1</span>])</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"variable language_\">self</span>.training <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> torch.jit.is_scripting():</span><br><span class=\"line\">                <span class=\"comment\"># 在训练并且不是在 TorchScript 编译模式下，返回两个头的输出，以便分别计算损失</span></span><br><span class=\"line\">                <span class=\"keyword\">return</span> x_cls,x_dist</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                <span class=\"comment\"># 在评估时，返回两个头输出的平均值作为最终预测</span></span><br><span class=\"line\">                <span class=\"keyword\">return</span> (x_cls + x_dist) / <span class=\"number\">2</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 标准模式下，直接将特征通过分类头</span></span><br><span class=\"line\">            x = <span class=\"variable language_\">self</span>.head(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> x        </span><br></pre></td></tr></table></figure>\n\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><strong>蒸馏模式与 dist_token</strong><br>代码里的“蒸馏模式”来源于一篇非常重要的论文 DeiT (Data-efficient Image Transformers)。<br>(1)什么是知识蒸馏 (Knowledge Distillation)？<br>这是一种模型压缩和迁移学习的技术，核心思想是让一个强大而复杂的“教师模型”来指导一个轻量级的“学生模型”进行学习。</p>\n<ul>\n<li>教师模型: 通常是一个已经在大规模数据集上训练好的、性能非常强的模型（比如一个超大的 ResNet 或者另一个 ViT）。</li>\n<li>学生模型: 我们当前正在训练的模型（比如这个 VisionTransformer）。<br>指导的方式不仅仅是让学生模型学习正确的标签（比如图片是“猫”），还会让它学习教师模型输出的“软标签”。软标签是指教师模型对所有类别的预测概率分布，例如它可能认为图片是“猫”的概率是85%，是“狗”的概率是10%，是“老虎”的… 这个概率分布包含了教师模型“思考过程”的丰富信息。</li>\n</ul>\n<p>(2)为什么 ViT 需要蒸馏？<br>原始的 ViT 需要在海量的数据集（如谷歌内部的 JFT-300M，包含3亿张图片）上预训练才能获得优异的性能。如果只在 ImageNet-1k（约120万张图片）这种“中等”规模的数据集上从头训练，效果往往不如经典的 CNN 模型。<br>DeiT 论文发现，通过知识蒸馏，可以让一个 ViT 在仅使用 ImageNet-1k 的情况下，达到甚至超过在 JFT-300M 上预训练的效果，极大地提高了 ViT 的数据效率。</p>\n<p>(3)dist_token 的作用<br>DeiT 论文提出了一种新颖的蒸馏方式，就是通过添加一个专门用于蒸馏的 distillation token（即 dist_token）。</p>\n<ul>\n<li>cls_token 的任务: 和原来一样，它的最终输出用来和真实的标签 (ground-truth label) 计算损失，我们称之为“硬标签损失”。</li>\n<li>dist_token 的任务: 它是一个和 cls_token 地位相同的可学习向量，也被拼接到序列中，通过 Transformer 网络。但它的最终输出是专门用来和教师模型的预测（软标签或硬标签） 计算损失的，我们称之为“蒸馏损失”。</li>\n</ul>\n<p>通过这种方式，模型在训练时会同时优化两个目标：</p>\n<ol>\n<li>让 cls_token 的输出尽可能接近真实答案。</li>\n<li>让 dist_token 的输出尽可能模仿教师模型的答案。<br>这种双重监督机制被证明非常有效，dist_token 就像一个专门负责从教师那里“偷师学艺”的通道，帮助学生模型学得更好。</li>\n</ol></blockquote>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><strong>pre-logits 层的作用</strong><br>pre-logits 层，可以理解为一个在最终分类头（self.head）之前的一个特征处理/映射层。它的主要作用是为了更好地进行迁移学习。<br>想象一个场景：</p>\n<ol>\n<li>一个机构（比如谷歌）在一个超级庞大的私有数据集（比如 JFT-300M，有18000个类别）上预训练了一个 ViT 模型。</li>\n<li>这个预训练模型的最终分类头是 nn.Linear(embed_dim, 18000)。</li>\n<li>现在你想把这个模型用到你自己的任务上，比如一个只有10个类别的猫狗分类任务。</li>\n</ol>\n<p>显然，那个输出18000个维度的分类头对你来说是没用的。但是，它之前的网络层学到的特征提取能力是非常宝贵的。<br>在这种情况下，pre-logits 层就派上用场了：</p>\n<ul>\n<li>它通常是一个 nn.Linear(embed_dim, representation_size) 加上一个激活函数（如 Tanh）。</li>\n<li>在预训练时，模型会先将 cls_token 的输出通过这个 pre-logits 层，得到一个固定维度的“特征表示” (representation)，然后再将这个表示送入最终的分类头。</li>\n<li>当你拿到这个预训练模型进行迁移学习时，你可以丢弃掉原有的最终分类头，但保留 pre-logits 层。然后，你只需要在 pre-logits 层的输出后面接上你自己任务的分类头，例如 nn.Linear(representation_size, 10)。</li>\n</ul></blockquote>\n<h3 id=\"5-创建应用层\"><a href=\"#5-创建应用层\" class=\"headerlink\" title=\"5. 创建应用层\"></a>5. 创建应用层</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">vit_base_patch16_224</span>(<span class=\"params\">num_classes:<span class=\"built_in\">int</span> =<span class=\"number\">100</span>, pretrained=<span class=\"literal\">False</span></span>):</span><br><span class=\"line\">    model = VisionTransformer(img_size=<span class=\"number\">224</span>,</span><br><span class=\"line\">                              patch_size=<span class=\"number\">16</span>,</span><br><span class=\"line\">                              embed_dim=<span class=\"number\">768</span>,</span><br><span class=\"line\">                              depth=<span class=\"number\">12</span>,</span><br><span class=\"line\">                              num_head=<span class=\"number\">12</span>,</span><br><span class=\"line\">                              representation_size=<span class=\"literal\">None</span>,</span><br><span class=\"line\">                              num_classes=num_classes)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> model</span><br></pre></td></tr></table></figure>","text":"参考笔记：ViT讲解 Vision Transformer的出现标志着 Transformer 架构成功应用于计算机视觉领域，挑战了卷积神经网络在该领域的主导地...","permalink":"/post/ViT精读","photos":[],"count_time":{"symbolsCount":"21k","symbolsTime":"19 mins."},"categories":[],"tags":[{"name":"Vision-Transformer","slug":"Vision-Transformer","count":1,"path":"api/tags/Vision-Transformer.json"},{"name":"深度学习","slug":"深度学习","count":1,"path":"api/tags/深度学习.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#I-%E6%91%98%E8%A6%81\"><span class=\"toc-text\">I. 摘要</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#II-%E5%88%9B%E6%96%B0%E7%82%B9\"><span class=\"toc-text\">II. 创新点</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%8C%83%E5%BC%8F%E9%9D%A9%E6%96%B0%EF%BC%9A%E5%B0%86%E5%9B%BE%E5%83%8F%E8%A7%86%E4%B8%BA%E5%BA%8F%E5%88%97%E5%A4%84%E7%90%86\"><span class=\"toc-text\">范式革新：将图像视为序列处理</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E9%87%8F%E8%83%9C%E4%BA%8E%E5%BD%92%E7%BA%B3%E5%81%8F%E7%BD%AE\"><span class=\"toc-text\">数据量胜于归纳偏置</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%8D%93%E8%B6%8A%E7%9A%84%E8%AE%A1%E7%AE%97%E6%95%88%E7%8E%87%E5%92%8C%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7\"><span class=\"toc-text\">卓越的计算效率和可扩展性</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%AE%80%E6%B4%81%E8%80%8C%E6%9C%89%E6%95%88%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1\"><span class=\"toc-text\">简洁而有效的模型设计</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#III-%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3\"><span class=\"toc-text\">III. 网络原理详解</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#ViT%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%A7%88\"><span class=\"toc-text\">ViT模型概览</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%9B%BE%E5%83%8F%E5%88%86%E5%9D%97%E5%A4%84%E7%90%86-Image-Patching\"><span class=\"toc-text\">图像分块处理 (Image Patching)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%8F%AF%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%88%86%E7%B1%BB%E5%B5%8C%E5%85%A5-Class-Token\"><span class=\"toc-text\">可学习的分类嵌入 (Class Token)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%9E%8D%E5%90%88%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81-Positional-Encoding\"><span class=\"toc-text\">融合位置编码 (Positional Encoding)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Transformer-Encoder\"><span class=\"toc-text\">Transformer Encoder</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#MLP-Head-%E5%88%86%E7%B1%BB%E5%A4%B4\"><span class=\"toc-text\">MLP Head (分类头)</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#IV-ViT%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0\"><span class=\"toc-text\">IV. ViT代码复现</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-Patch-Embedding\"><span class=\"toc-text\">1. Patch Embedding</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-multi-head\"><span class=\"toc-text\">2. multi-head</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-Block\"><span class=\"toc-text\">3. Block</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#4-Vision-Transformer\"><span class=\"toc-text\">4. Vision Transformer</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-%E5%88%9B%E5%BB%BA%E5%BA%94%E7%94%A8%E5%B1%82\"><span class=\"toc-text\">5. 创建应用层</span></a></li></ol></li></ol>","author":{"name":"犬夜叉","slug":"blog-author","avatar":"https://i.imgur.com/CrgPA5H.png","link":"/","description":"一位喜欢犬夜叉的多模态大模型研究生","socials":{"github":"https://github.com/ziyi-wang2003","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/qq_62954485?spm=1000.2115.3001.5343","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{},"next_post":{}}